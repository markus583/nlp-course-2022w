{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
    "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
    "| <p style=\"text-align: left\">Markus</p>| <p style=\"text-align: left\">Frohmann</p> | k12005604 |\n",
    "| <p style=\"text-align: left\">Tobias</p>| <p style=\"text-align: left\">Morocutti</p> | k12008172 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2 style=\"text-align: center\">344.075 KV: Natural Language Processing (WS2022/23)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 3</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Document Classification with PyTorch and BERT</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University Linz (JKU), and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Author:** Navid Rekab-saz<br>\n",
    "**Email:** navid.rekabsaz@jku.at<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-tensorboard\"><li style=\"font-size:large;font-weight:bold\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Document Classification with PyTorch (25 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with BERT (15 points)</li></a>\n",
    "    \n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Assignment objective\n",
    "This assignment aims to provide the necessary practices for learning the principles of deep learning programing in NLP using PyTorch. To this end, Task A provides the space for becoming fully familiar with PyTorch programming by implementing a \"simple\" document (sentence) classification model with PyTorch, and Task B extends this classifier with a BERT model. As the assignment requires working with PyTorch and Huggingface Transformers, please familiarize yourself with these libraries using any possible available teaching resources in particular the libraries' documentations. The assignment has in total **40 points**, and also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python`, `PyTorch` and, `transformers`. Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project – an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points. \n",
    "\n",
    "Download the dataset from [this link](https://drive.jku.at/filr/public-link/file-download/0cce88f083887a0401841aee8fab3d36/44093/-2905493136371866025/nlp2022_23_data.zip).\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.label.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.* \n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook. \n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name=\"section-tensorboard\"></a><h2 style=\"color:rgb(0,120,170)\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "In all experiments of this assignment, use any experiment monitoring tool like [`TensorBoard`](https://www.tensorflow.org/tensorboard), [`wandb`](https://wandb.ai) to log and store all useful information about the training and evaluation of the models. Feel free to log any important aspect in particular the changes in evaluation results on validation, in training loss, and in learning rate.\n",
    "\n",
    "After finalizing all experiments and cleaning any unnecessary experiment, **provide the URL to the results monitoring page in the cell below**.\n",
    "\n",
    "For instance if using [`TensorBoard.dev`](https://tensorboard.dev), you can run the following command in the folder of log files: `tensorboard dev upload --name my_exp --logdir path/to/output_dir`, and take the provided URL to the TensorBoard's console.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**URL :** *EDIT!*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Document Classification with PyTorch (25 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "The aim of this task is identical to the one of Assignment 2 - Task B, namely to design a document classification model that exploits pre-trained word embeddings. It is of course allowed to use the preprocessed text, the dictionary, or any other relevant code or processings, done in the previous assignments.\n",
    "\n",
    "In this task, you implement a document classification model using PyTorch, which given a document/sentence (consisting of a set of words) predicts the corresponding class. Before getting started with coding, have a look at the optional <a href=\"#section-tensorboard\">Task C</a>, as you may want to already include `Tensorboard` in the code. The implementation of the classifier should cover the points below.\n",
    "\n",
    "**Preprocessing and dictionary (1 point):** Following previous assignments, load the train, validation, and test datasets, apply necessary preprocessing steps, and create a dictionary of words. \n",
    "\n",
    "**Data batching (4 points):** Using the dictionary, create batches for any given dataset (train/validation/test). Each batch is a two-dimensional matrix of *batch-size* to *max-document-length*, containing the IDs of the words in the corresponding documents. *Batch-size* and *max-document-length* are two hyper-parameters and can be set to any appropriate values (*Batch-size* must be higher than 1 and *max-document-length* at least 50 words). If a document has more than *max-document-length* words, only the first *max-document-length* words should be kept.\n",
    "\n",
    "**Word embedding lookup (2 point):** Using `torch.nn.Embedding`, create a lookup for the embeddings of all the words in the dictionary. The lookup is in fact a matrix, which maps the ID of each word to the corresponding word vector. Similar to Assignment 2, use the pre-trained vectors of a word embedding model (like word2vec or GloVe) to initialize the word embeddings of the lookup. Keep in mind that the embeddings of the words in the lookup should be matched with the correct vector in the pretrained word embedding. If the vector of a word in the lookup does not exist in the pretrained word embeddings, the corresponding vector should be initialized randomly. \n",
    "\n",
    "**Model definition (3 points):** Define the class `ClassificationAverageModel` as a PyTorch model. In the initialization procedure, the model receives the word embedding lookup, and includes it in the model as model's parameters. These embeddings parameters should be trainable, meaning that the word vectors get updated during model training. Feel free to add any other parameters to the model, which might be necessary for accomplishing the functionalities explained in the following.\n",
    "\n",
    "**Forward function (5 points):** The forward function of the model receives a batch of data, and first fetches the corresponding embeddings of the word IDs in the batch using the lookup. Similar to Assignment 2, the embedding of a document is created by calculating the *element-wise mean* of the embeddings of the document's words. Formally, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "<center><div>$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$</div></center>\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document. An important point in the implementation of this formula is that the documents in the batch might have different lengths and therefore each document should be divided by its corresponding $|d|$. Finally, this document embedding is utilized to predict the probability of the output classes, done by applying a linear transformation from the embeddings size to the number of classes, followed by Softmax. The linear transformation also belongs to the model's parameters and will be learned in training.\n",
    "\n",
    "**Loss Function and optimization (2 point):** The loss between the predicted and the actual classes is calculated using Negative Log Likelihood or Cross Entropy. Update the model's parameters using any appropriate optimization mechanism such as Adam.\n",
    "\n",
    "**Early Stopping (2 points):** After each epoch, evaluate the model on the *validation set* using accuracy. If the evaluation result (accuracy) improves, save the model as the best performing one so far. If the results are not improving after a certain number of evaluation rounds (set as another hyper-parameter) or if training reaches a certain number of epochs, terminate the training procedure. \n",
    "\n",
    "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
    "\n",
    "**Reporting (1 point):** During loading and processing the collection, provide sufficient information and examples about the data and the applied processing steps. Report the results of the best performing model on the validation and test set in a table.\n",
    "\n",
    "**Overall functionality of the training procedure (4 point).**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODOs\n",
    "Ranked by importance, kind of"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# TODO: Bonus Task - experiment tracking\n",
    "\n",
    "# TODO: check whether BERT tokenization is correct\n",
    "# TODO: check BERT forward loop - can we avoid LogSoftmax?!\n",
    "# TODO: make all training compatible with GPU loops - .to(device)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: improve BERT performance - should be at least >= AverageModel's performance (or > 0.8, say)\n",
    "# TODO: test BERT training with Cross Entropy instead of NLLLoss\n",
    "# TODO: for \"Reporting\" section (Task A & B), add more metrics (e.g. precision, recall, f1-score, ...)\n",
    "\n",
    "# TODO: simplify & clean up code - especially training loop & batching functions\n",
    "\n",
    "# TODO: hyperparameter tuning (lr, epochs, batch size, max_seq_len, optimizer, preprocessing, ...)\n",
    "# TODO: provide some more examples, info & explanations\n",
    "# TODO: try other BERT models? (not tiny)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing and dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following previous assignments, load the train, validation, and test datasets, apply necessary preprocessing steps, and create a dictionary of words."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data and Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the train, validation, and test sets\n",
    "BASE_DIR = 'data/nlp2022_23_data/'\n",
    "TRAIN_FILE = BASE_DIR + 'thedeep.subset' + '.train.txt'\n",
    "VAL_FILE = BASE_DIR + 'thedeep.subset' + '.validation.txt'\n",
    "TEST_FILE = BASE_DIR + 'thedeep.subset' + '.test.txt'\n",
    "LABEL_FILE = BASE_DIR + 'thedeep.' + 'labels.txt'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_FILE, sep=',', header=None, names=['sentence_id', 'text', 'label'])\n",
    "val_df = pd.read_csv(VAL_FILE, sep=',', header=None, names=['sentence_id', 'text', 'label'])\n",
    "test_df = pd.read_csv(TEST_FILE, sep=',', header=None, names=['sentence_id', 'text', 'label'])\n",
    "label_df = pd.read_csv(LABEL_FILE, sep=',', header=None, names=['label', 'caption'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length:  12110\n",
      "Validation set length:  2596\n",
      "Test set length:  2595\n"
     ]
    }
   ],
   "source": [
    "# print length of each set\n",
    "print('Train set length: ', len(train_df))\n",
    "print('Validation set length: ', len(val_df))\n",
    "print('Test set length: ', len(test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of text in train set:  450.86\n",
      "Average length of text in validation set:  446.5\n",
      "Average length of text in test set:  440.51\n"
     ]
    }
   ],
   "source": [
    "# print average length of text in each set\n",
    "print('Average length of text in train set: ', np.round(np.mean(train_df['text'].str.len()), 2))\n",
    "print('Average length of text in validation set: ', np.round(np.mean(val_df['text'].str.len()), 2))\n",
    "print('Average length of text in test set: ', np.round(np.mean(test_df['text'].str.len()), 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    label      caption\n0       0  Agriculture\n1       1        Cross\n2       2    Education\n3       3         Food\n4       4       Health\n5       5   Livelihood\n6       6     Logistic\n7       7          NFI\n8       8    Nutrition\n9       9   Protection\n10     10      Shelter\n11     11         WASH",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Agriculture</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Cross</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Education</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Health</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Livelihood</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Logistic</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>NFI</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Nutrition</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Protection</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>Shelter</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>WASH</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each label corresponds to a given caption, i.e., a category."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def map_label_to_caption(label):\n",
    "    \"\"\"\n",
    "    Map label id to caption using label_df\n",
    "    :param label: label id, int\n",
    "    :return: label caption, str\n",
    "    \"\"\"\n",
    "    return label_df[label_df['label'] == label]['caption'].values[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_df = train_df.assign(caption=train_df['label'].apply(map_label_to_caption))\n",
    "val_df = val_df.assign(caption=val_df['label'].apply(map_label_to_caption))\n",
    "test_df = test_df.assign(caption=test_df['label'].apply(map_label_to_caption))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# remove punctuation marks, replace dates & numbers, apply case-sensitivity\n",
    "# do this in order to reduce the size of the dictionary & reduce complexity\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing punctuation marks, replacing dates & numbers, applying case-sensitivity\n",
    "    :param text: text to clean, str\n",
    "    :return: cleaned text, str\n",
    "    \"\"\"\n",
    "    # remove punctuation marks\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # replace dates\n",
    "    text = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '< date >', text)\n",
    "    # replace numbers\n",
    "    text = re.sub(r'\\d+', '< num >', text)\n",
    "    # apply case-sensitivity\n",
    "    text = text.lower()\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
    "val_df['cleaned_text'] = val_df['text'].apply(clean_text)\n",
    "test_df['cleaned_text'] = test_df['text'].apply(clean_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       sentence_id                                               text  label  \\\n0             5446  In addition to the immediate life-saving inter...      9   \n1             8812  There are approximately 2.6 million people cla...      3   \n2            16709  While aid imports have held up recently, comme...      5   \n3             3526  Heavy rainfalls as well as onrush of water fro...      0   \n4             4928  Based on field reports 9 , the main production...      3   \n...            ...                                                ...    ...   \n12105        12744  The total gap in the number of people who requ...      8   \n12106         9655  A food crisis is looming in the country with t...      0   \n12107         6963  ? Acute watery diarrhoea (AWD) continues to be...      4   \n12108          923  As South India grapples with drought and water...     11   \n12109        15880  Mirroring trends in South Africa, the main sou...      3   \n\n           caption                                       cleaned_text  \n0       Protection  in addition to the immediate life-saving inter...  \n1             Food  there are approximately < num >.< num > millio...  \n2       Livelihood  while aid imports have held up recently, comme...  \n3      Agriculture  heavy rainfalls as well as onrush of water fro...  \n4             Food  based on field reports < num > , the main prod...  \n...            ...                                                ...  \n12105    Nutrition  the total gap in the number of people who requ...  \n12106  Agriculture  a food crisis is looming in the country with t...  \n12107       Health  ? acute watery diarrhoea (awd) continues to be...  \n12108         WASH  as south india grapples with drought and water...  \n12109         Food  mirroring trends in south africa, the main sou...  \n\n[12110 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>caption</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5446</td>\n      <td>In addition to the immediate life-saving inter...</td>\n      <td>9</td>\n      <td>Protection</td>\n      <td>in addition to the immediate life-saving inter...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8812</td>\n      <td>There are approximately 2.6 million people cla...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>there are approximately &lt; num &gt;.&lt; num &gt; millio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16709</td>\n      <td>While aid imports have held up recently, comme...</td>\n      <td>5</td>\n      <td>Livelihood</td>\n      <td>while aid imports have held up recently, comme...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3526</td>\n      <td>Heavy rainfalls as well as onrush of water fro...</td>\n      <td>0</td>\n      <td>Agriculture</td>\n      <td>heavy rainfalls as well as onrush of water fro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4928</td>\n      <td>Based on field reports 9 , the main production...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>based on field reports &lt; num &gt; , the main prod...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12105</th>\n      <td>12744</td>\n      <td>The total gap in the number of people who requ...</td>\n      <td>8</td>\n      <td>Nutrition</td>\n      <td>the total gap in the number of people who requ...</td>\n    </tr>\n    <tr>\n      <th>12106</th>\n      <td>9655</td>\n      <td>A food crisis is looming in the country with t...</td>\n      <td>0</td>\n      <td>Agriculture</td>\n      <td>a food crisis is looming in the country with t...</td>\n    </tr>\n    <tr>\n      <th>12107</th>\n      <td>6963</td>\n      <td>? Acute watery diarrhoea (AWD) continues to be...</td>\n      <td>4</td>\n      <td>Health</td>\n      <td>? acute watery diarrhoea (awd) continues to be...</td>\n    </tr>\n    <tr>\n      <th>12108</th>\n      <td>923</td>\n      <td>As South India grapples with drought and water...</td>\n      <td>11</td>\n      <td>WASH</td>\n      <td>as south india grapples with drought and water...</td>\n    </tr>\n    <tr>\n      <th>12109</th>\n      <td>15880</td>\n      <td>Mirroring trends in South Africa, the main sou...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>mirroring trends in south africa, the main sou...</td>\n    </tr>\n  </tbody>\n</table>\n<p>12110 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\marku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# use NLTK tokenizer (TreebankWordTokenizer)\n",
    "from nltk.tokenize import word_tokenize\n",
    "train_df['tokenized_text'] = train_df['cleaned_text'].apply(word_tokenize)\n",
    "val_df['tokenized_text'] = val_df['cleaned_text'].apply(word_tokenize)\n",
    "test_df['tokenized_text'] = test_df['cleaned_text'].apply(word_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# remove stopwords in English in order to reduce the size of the dictionary\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_df['tokenized_text'] = train_df['tokenized_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "val_df['tokenized_text'] = val_df['tokenized_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "test_df['tokenized_text'] = test_df['tokenized_text'].apply(lambda x: [word for word in x if word not in stop_words])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# create dictionary using train set\n",
    "def create_dictionary(tokenized_text):\n",
    "    \"\"\"\n",
    "    Create dictionary using train set\n",
    "    :param tokenized_text: tokenized text, list\n",
    "    :return: dictionary, dict\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    for tokens in tokenized_text:\n",
    "        for token in tokens:\n",
    "            if token not in dictionary:\n",
    "                dictionary[token] = 1\n",
    "            else:\n",
    "                dictionary[token] += 1\n",
    "    return dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "dictionary = create_dictionary(train_df['tokenized_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dictionary:  31363\n"
     ]
    }
   ],
   "source": [
    "# print length of dictionary\n",
    "print('Length of dictionary: ', len(dictionary))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# keep only top-N most frequent words\n",
    "# removing any word with a lower frequency than a threshold\n",
    "# OOV (out-of-vocabulary) words will be replaced with the <oov> token\n",
    "def clean_dictionary(dictionary, N: int, threshold: int):\n",
    "    \"\"\"\n",
    "    Clean dictionary by keeping only top-N most frequent words and removing any word with a lower frequency than a threshold\n",
    "    :param dictionary: dictionary, dict\n",
    "    :param N: top-N most frequent words, int\n",
    "    :param threshold: threshold of word frequency, int\n",
    "    :return: cleaned dictionary, dict\n",
    "    \"\"\"\n",
    "    # keep only top-N most frequent words\n",
    "    dictionary = dict(sorted(dictionary.items(), key=lambda x: x[1], reverse=True)[:N])\n",
    "\n",
    "    # replace any word with a lower frequency than a threshold\n",
    "    for key, value in dictionary.copy().items():\n",
    "        if value < threshold:\n",
    "            dictionary['<oov>'] = dictionary.get('<oov>', 0) + value\n",
    "            dictionary.pop(key)\n",
    "    return dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dictionary = clean_dictionary(dictionary, N=100_000, threshold=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dictionary:  8247\n"
     ]
    }
   ],
   "source": [
    "# print length of dictionary\n",
    "print('Length of dictionary: ', len(dictionary))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{',': 51067,\n '<': 50593,\n '>': 50580,\n 'num': 50536,\n '.': 35521,\n ')': 9820,\n '(': 9808,\n 'cases': 4751,\n 'food': 4133,\n '%': 4025,\n 'people': 3856,\n 'reported': 3670,\n '’': 2955,\n 'children': 2942,\n 'areas': 2541,\n 'water': 2511,\n 'health': 2477,\n 'said': 1921,\n 'access': 1828,\n 'including': 1794,\n 'per': 1699,\n 'also': 1691,\n 'percent': 1655,\n ':': 1650,\n 'due': 1638,\n 'affected': 1638,\n 'since': 1600,\n 'deaths': 1469,\n 'number': 1404,\n 'households': 1381,\n '“': 1367,\n 'total': 1352,\n 'country': 1345,\n '”': 1343,\n 'humanitarian': 1321,\n 'two': 1318,\n 'security': 1308,\n 'week': 1302,\n 'million': 1297,\n 'one': 1284,\n 'prices': 1268,\n 'state': 1247,\n 'new': 1246,\n 'government': 1237,\n 'cent': 1235,\n 'refugees': 1227,\n 'year': 1219,\n '-': 1148,\n 'displaced': 1147,\n 'assistance': 1131,\n 'according': 1120,\n 'cholera': 1115,\n 'phase': 1114,\n 'need': 1114,\n ';': 1090,\n 'south': 1076,\n 'suspected': 1075,\n 'women': 1074,\n 'high': 1068,\n 'ipc': 1065,\n 'acute': 1060,\n 'region': 1055,\n 'may': 1034,\n 'season': 1029,\n 'many': 1028,\n 'last': 1001,\n 'outbreak': 1000,\n 'area': 977,\n 'population': 973,\n 'three': 971,\n 'services': 970,\n 'situation': 953,\n '?': 953,\n 'emergency': 943,\n 'malnutrition': 922,\n 'families': 902,\n 'idps': 900,\n 'january': 899,\n 'local': 888,\n 'average': 887,\n '–': 884,\n 'increased': 883,\n 'poor': 875,\n 'confirmed': 871,\n 'insecurity': 867,\n 'increase': 850,\n 'case': 837,\n 'march': 830,\n 'lack': 829,\n 'city': 814,\n 'crisis': 812,\n 'across': 810,\n 'expected': 804,\n 'years': 803,\n 'risk': 803,\n 'needs': 799,\n 'facilities': 778,\n 'among': 777,\n 'least': 770,\n 'schools': 766,\n 'support': 754,\n 'camps': 749,\n 'school': 746,\n 'conflict': 743,\n 'estimated': 732,\n 'however': 728,\n 'production': 723,\n 'conditions': 721,\n 'compared': 718,\n 'medical': 715,\n 'february': 709,\n 'five': 702,\n 'communities': 700,\n 'levels': 697,\n 'national': 694,\n 'april': 694,\n 'months': 684,\n 'remain': 677,\n 'violence': 675,\n 'continue': 670,\n 'camp': 664,\n 'education': 664,\n 'likely': 661,\n 'authorities': 657,\n 'sudan': 656,\n \"'s\": 652,\n '•': 651,\n 'response': 646,\n 'period': 643,\n 'rate': 641,\n 'well': 635,\n 'still': 628,\n 'limited': 627,\n 'human': 625,\n 'armed': 623,\n 'protection': 614,\n 'rights': 614,\n 'june': 613,\n 'care': 608,\n 'central': 607,\n 'october': 606,\n 'severe': 604,\n 'december': 597,\n 'regions': 596,\n 'killed': 592,\n 'states': 580,\n 'september': 578,\n 'refugee': 571,\n 'report': 569,\n 'rains': 565,\n 'maize': 561,\n 'sites': 558,\n 'forces': 558,\n 'community': 556,\n 'four': 548,\n 'province': 544,\n 'main': 542,\n 'northern': 539,\n 'livestock': 538,\n 'district': 538,\n 'districts': 537,\n 'east': 533,\n 'hospital': 529,\n 'living': 528,\n \"'\": 528,\n 'groups': 527,\n 'west': 520,\n 'ongoing': 518,\n 'recorded': 517,\n 'north': 516,\n 'first': 515,\n 'following': 510,\n 'civilians': 508,\n 'month': 507,\n 'august': 504,\n 'around': 503,\n 'international': 502,\n 'eastern': 499,\n 'currently': 498,\n 'parts': 495,\n 'reports': 493,\n 'nutrition': 492,\n 'markets': 487,\n 'rainfall': 486,\n 'particularly': 484,\n 'recent': 483,\n 'time': 482,\n 'aid': 481,\n 'remains': 481,\n 'displacement': 476,\n 'town': 471,\n 'result': 461,\n 'july': 459,\n 'early': 459,\n 'al': 459,\n 'disease': 458,\n 'southern': 455,\n 'drought': 455,\n 'several': 454,\n 'partners': 453,\n 'vulnerable': 452,\n 'november': 451,\n 'market': 449,\n 'shelter': 448,\n 'activities': 447,\n 'weeks': 446,\n 'patients': 446,\n 'basic': 443,\n 'continued': 443,\n 'treatment': 441,\n 'idp': 439,\n 'residents': 439,\n 'could': 438,\n 'assessment': 437,\n 'houses': 435,\n 'low': 434,\n 'gaza': 433,\n 'military': 431,\n 'border': 428,\n 'israeli': 428,\n 'ministry': 427,\n 'girls': 427,\n 'supplies': 427,\n 'level': 422,\n 'majority': 422,\n 'death': 414,\n 'already': 413,\n 'attacks': 413,\n 'un': 412,\n 'el': 410,\n 'continues': 406,\n 'measles': 406,\n 'harvest': 406,\n 'six': 405,\n 'days': 403,\n 'forced': 402,\n 'homes': 401,\n 'damaged': 397,\n 'higher': 396,\n 'host': 395,\n 'price': 393,\n 'reportedly': 390,\n 'past': 390,\n 'public': 389,\n 'palestinian': 388,\n 'available': 384,\n 'syrian': 383,\n 'supply': 382,\n 'even': 380,\n 'land': 380,\n 'day': 379,\n 'shelters': 377,\n 'county': 373,\n 'group': 372,\n 'agricultural': 372,\n 'within': 371,\n 'fever': 370,\n 'villages': 367,\n 'previous': 366,\n 'told': 365,\n 'increasing': 365,\n 'destroyed': 364,\n 'end': 364,\n 'household': 362,\n 'current': 360,\n 'without': 359,\n 'child': 357,\n 'crops': 355,\n 'face': 355,\n 'died': 354,\n 'nearly': 353,\n 'age': 353,\n 'counties': 350,\n 'injured': 350,\n 'sources': 350,\n 'would': 349,\n 'especially': 348,\n 'major': 347,\n 'return': 346,\n 'police': 345,\n 'availability': 343,\n 'reporting': 343,\n 'severely': 342,\n 'unhcr': 341,\n 'cfr': 339,\n 'syria': 337,\n 'approximately': 336,\n 'significant': 336,\n 'safe': 336,\n 'sanitation': 336,\n 'wash': 334,\n 'beginning': 334,\n 'critical': 333,\n 'western': 332,\n 'received': 331,\n 'heavy': 329,\n 'rates': 329,\n 'addition': 328,\n 'half': 328,\n 'additional': 328,\n 'caused': 327,\n 'less': 323,\n 'provide': 323,\n 'river': 323,\n 'members': 321,\n 'despite': 321,\n 'crop': 318,\n 'rural': 318,\n 'diseases': 318,\n 'concern': 316,\n 'world': 313,\n 'malaria': 313,\n 'highest': 312,\n 'near': 309,\n 'lower': 308,\n 'work': 304,\n 'impact': 304,\n 'men': 304,\n 'control': 303,\n 'use': 303,\n 'found': 303,\n 'others': 301,\n 'primary': 301,\n 'unicef': 299,\n 'identified': 299,\n 'fuel': 298,\n 'large': 298,\n 'capacity': 297,\n 'far': 295,\n 'provinces': 295,\n 'locations': 292,\n 'overall': 291,\n 'almost': 290,\n 'management': 289,\n 'provided': 289,\n 'system': 288,\n 'capital': 287,\n 'settlements': 287,\n 'outcomes': 287,\n 'family': 287,\n 'damage': 286,\n 'although': 285,\n 'populations': 285,\n 'persons': 284,\n 'figure': 284,\n 'centre': 284,\n 'insecure': 283,\n 'income': 283,\n 'dengue': 282,\n 'part': 282,\n '/': 282,\n 'facing': 282,\n 'attack': 281,\n 'rice': 280,\n 'needed': 280,\n 'nigeria': 279,\n 'yemen': 278,\n 'centres': 278,\n 'workers': 277,\n 'migrants': 276,\n 'fatality': 276,\n 'source': 276,\n 'information': 275,\n 'lean': 275,\n 'thousands': 273,\n 'livelihood': 272,\n 'darfur': 271,\n 'fighting': 270,\n 'laboratory': 270,\n 'reduced': 270,\n 'left': 269,\n 'consumption': 268,\n 'resources': 268,\n 'official': 267,\n 'somali': 265,\n 'seven': 264,\n 'rohingya': 264,\n 'normal': 263,\n 'used': 262,\n 'drinking': 261,\n 'wfp': 260,\n 'sam': 259,\n 'spread': 259,\n 'borno': 259,\n 'positive': 259,\n 'improved': 258,\n 'movement': 258,\n 'livelihoods': 257,\n 'floods': 257,\n 'registered': 256,\n 'conducted': 256,\n 'remained': 256,\n 'staple': 256,\n 'somalia': 255,\n 'power': 255,\n 'village': 254,\n 'along': 253,\n 'late': 253,\n 'farmers': 251,\n 'sexual': 251,\n 'civilian': 248,\n 'sector': 247,\n 'incidents': 247,\n 'th': 246,\n 'data': 242,\n 'countries': 241,\n 'hygiene': 241,\n 'casualties': 240,\n 'significantly': 240,\n 'operations': 240,\n 'second': 240,\n 'governorates': 239,\n 'army': 239,\n 'organization': 238,\n 'kenya': 238,\n 'bank': 237,\n 'working': 236,\n 'staff': 236,\n 'place': 235,\n 'nile': 235,\n 'led': 234,\n 'respectively': 233,\n 'another': 232,\n '$': 232,\n 'live': 231,\n 'serious': 230,\n 'harvests': 229,\n 'mainly': 229,\n 'started': 228,\n 'says': 227,\n 'opportunities': 227,\n 'concerns': 227,\n 'gam': 226,\n 'pastoral': 226,\n 'start': 226,\n 'relief': 226,\n 'located': 225,\n 'flooding': 225,\n 'cereal': 225,\n 'outbreaks': 224,\n 'hospitals': 224,\n 'urgent': 223,\n 'closed': 223,\n 'officials': 222,\n 'include': 222,\n 'infrastructure': 222,\n 'agency': 221,\n 'stressed': 221,\n 'often': 220,\n 'ethiopia': 220,\n 'rainy': 219,\n 'service': 219,\n 'dry': 219,\n 'governorate': 218,\n 'reached': 218,\n 'open': 218,\n 'based': 217,\n 'distribution': 217,\n 'red': 216,\n 'close': 216,\n 'able': 215,\n 'affecting': 215,\n 'resulted': 215,\n 'media': 215,\n 'targeted': 215,\n 'numbers': 215,\n 'home': 215,\n 'given': 214,\n 'zone': 214,\n 'individuals': 214,\n 'made': 213,\n 'hit': 213,\n 'arrivals': 213,\n 'myanmar': 211,\n 'site': 211,\n 'civil': 209,\n 'long': 209,\n 'outside': 209,\n 'teachers': 208,\n 'sudanese': 208,\n 'improve': 208,\n 'fled': 207,\n 'stocks': 207,\n 'key': 207,\n 'eight': 207,\n 'general': 205,\n 'efforts': 205,\n 'decline': 204,\n 'reach': 204,\n 'prevalence': 203,\n 'related': 202,\n 'monday': 201,\n 'items': 201,\n 'united': 200,\n 'republic': 200,\n 'risks': 200,\n 'meet': 199,\n 'awd': 199,\n 'zones': 199,\n 'malnourished': 199,\n 'actors': 198,\n 'require': 198,\n 'yet': 197,\n 'department': 197,\n 'us': 196,\n 'famine': 195,\n 'samples': 195,\n 'challenges': 194,\n 'students': 194,\n 'shortage': 193,\n 'global': 193,\n 'aged': 193,\n 'war': 191,\n 'using': 191,\n 'urban': 191,\n 'cluster': 191,\n 'trend': 191,\n 'decrease': 190,\n 'lives': 190,\n 'detention': 189,\n 'seasonal': 189,\n 'today': 188,\n 'results': 187,\n 'greater': 187,\n 'back': 187,\n 'economic': 186,\n 'violations': 186,\n 'agriculture': 186,\n 'arrived': 185,\n 'adequate': 185,\n 'ghouta': 185,\n 'radio': 185,\n 'held': 184,\n 'wheat': 184,\n 'electricity': 184,\n 'recently': 183,\n 'shortages': 183,\n 'resulting': 183,\n 'mostly': 182,\n 'plan': 182,\n 'latrines': 182,\n 'clashes': 182,\n 'road': 182,\n 'lost': 182,\n 'followed': 181,\n 'regional': 180,\n 'social': 180,\n 'cumulative': 180,\n 'healthcare': 179,\n 'suffering': 179,\n 'like': 178,\n 'development': 178,\n 'campaign': 178,\n 'transmission': 178,\n 'much': 178,\n 'throughout': 178,\n '‘': 177,\n 'negative': 176,\n 'rise': 176,\n 'hundreds': 175,\n 'restrictions': 175,\n 'returnees': 175,\n 'essential': 174,\n 'nine': 174,\n 'fire': 173,\n 'decreased': 173,\n 'minister': 173,\n 'funding': 173,\n 'law': 173,\n 'ensure': 172,\n 'taken': 172,\n 'pregnant': 172,\n 'required': 171,\n 'labor': 171,\n 'fall': 170,\n 'internally': 170,\n 'remaining': 170,\n 'sorghum': 170,\n 'observed': 170,\n 'latest': 170,\n 'safety': 169,\n 'order': 169,\n 'analysis': 169,\n 'earlier': 169,\n 'diarrhoea': 168,\n 'roads': 168,\n 'wednesday': 167,\n 'victims': 167,\n 'say': 166,\n 'measures': 166,\n 'occurred': 166,\n 'nations': 165,\n 'leading': 165,\n 'unable': 165,\n 'returned': 165,\n 'daily': 164,\n 'below-average': 164,\n 'injuries': 164,\n 'assessed': 164,\n 'young': 163,\n 'demand': 163,\n 'tuesday': 162,\n 'leaving': 162,\n 'experiencing': 162,\n 'next': 162,\n 'rain': 162,\n 'presence': 162,\n 'quality': 161,\n '[': 161,\n 'centers': 161,\n 'third': 161,\n 'coping': 160,\n 'interventions': 159,\n 'slightly': 159,\n 'increases': 159,\n 'take': 159,\n 'hours': 159,\n 'monitoring': 159,\n 'detained': 159,\n 'agencies': 158,\n 'help': 158,\n 'rapid': 158,\n 'boys': 158,\n 'libya': 158,\n 'niger': 157,\n 'away': 157,\n 'vaccination': 157,\n 'oromia': 157,\n 'trade': 157,\n 'imports': 156,\n 'either': 156,\n 'seen': 156,\n 'africa': 156,\n 'providing': 155,\n 'survey': 154,\n 'date': 154,\n 'cash': 154,\n 'journalists': 153,\n 'cross': 153,\n 'soldiers': 153,\n 'provision': 153,\n 'go': 153,\n 'probable': 153,\n 'possible': 152,\n 'difficult': 152,\n 'flood': 151,\n 'cost': 151,\n 'night': 151,\n ']': 150,\n 'important': 150,\n 'organizations': 150,\n 'temporary': 150,\n 'political': 149,\n 'mosul': 148,\n 'kordofan': 148,\n 'congo': 148,\n 'israel': 148,\n 'indicated': 146,\n 'office': 146,\n 'epidemic': 146,\n 'former': 146,\n 'active': 145,\n 'surveillance': 145,\n 'msf': 145,\n 'diphtheria': 145,\n 'lgas': 145,\n 'different': 144,\n 'experienced': 144,\n 'rakhine': 144,\n 'equatoria': 144,\n 'thursday': 143,\n 'see': 143,\n 'bangladesh': 143,\n 'pasture': 143,\n 'associated': 142,\n 'indicate': 142,\n 'leave': 142,\n 'small': 142,\n 'uganda': 142,\n 'receive': 142,\n 'classified': 141,\n 'arrested': 141,\n 'better': 141,\n 'coming': 141,\n 'medicines': 141,\n 'process': 141,\n 'operation': 140,\n 'buildings': 140,\n 'inside': 140,\n 'sea': 139,\n 'life': 139,\n 'learning': 139,\n 'sunday': 139,\n 'newly': 139,\n 'times': 139,\n 'largest': 139,\n 'friday': 139,\n 'programme': 139,\n 'settlement': 138,\n 'watch': 138,\n 'e': 138,\n 'facility': 138,\n 'disaster': 138,\n 'quarter': 138,\n 'carried': 137,\n 'commodities': 137,\n 'gaps': 137,\n 'make': 136,\n 'though': 136,\n 'opposition': 136,\n 'began': 136,\n 'impacted': 136,\n 'stable': 136,\n 'widespread': 135,\n 'become': 135,\n 'every': 135,\n 'prevent': 135,\n 'minimal': 135,\n 'good': 135,\n 'immediate': 134,\n 'center': 134,\n 'juba': 134,\n 'cattle': 134,\n 'tested': 134,\n 'move': 133,\n 'watery': 133,\n 'body': 133,\n 'added': 133,\n 'head': 133,\n 'influx': 133,\n 'building': 133,\n 'structures': 133,\n 'absence': 132,\n 'issues': 132,\n 'released': 132,\n 'net': 131,\n 'chronic': 131,\n 'inadequate': 131,\n 'declined': 131,\n 'causing': 130,\n 'systems': 130,\n 'president': 130,\n 'oil': 130,\n 'put': 129,\n 'ground': 129,\n 'jerusalem': 129,\n 'coordination': 128,\n 'turkey': 128,\n 'fear': 128,\n 'old': 128,\n 'private': 128,\n 'team': 127,\n 'coverage': 127,\n 'white': 127,\n 'council': 127,\n 'wau': 127,\n 'issued': 126,\n 'extremely': 126,\n 'teams': 126,\n 'female': 126,\n 'projected': 126,\n 'virus': 126,\n 'iom': 126,\n 'force': 125,\n 'attacked': 125,\n 'various': 125,\n 'lassa': 125,\n 'get': 125,\n 'action': 124,\n 'director': 124,\n 'neighbouring': 124,\n 'status': 124,\n 'committee': 124,\n 'meningitis': 124,\n 'foods': 124,\n 'asylum': 123,\n 'line': 123,\n 'killing': 123,\n 'existing': 123,\n 'field': 122,\n 'means': 122,\n 'present': 122,\n '*': 122,\n 'labour': 122,\n 'onset': 122,\n 'physical': 121,\n 'proportion': 121,\n 'infection': 121,\n 'terms': 121,\n 'hunger': 121,\n 'democratic': 121,\n 'scale': 121,\n 'extreme': 121,\n 'declared': 120,\n 'airstrikes': 120,\n 'gap': 120,\n 'explosive': 120,\n 'car': 119,\n 'dead': 119,\n 'similar': 119,\n 'mission': 119,\n 'secondary': 119,\n 'estimates': 119,\n 'domestic': 119,\n 'points': 119,\n 'burundi': 118,\n 'took': 118,\n 'construction': 118,\n 'potential': 118,\n 'weather': 118,\n 'gas': 118,\n 'receiving': 118,\n 'aleppo': 117,\n 'worst': 117,\n 'delivery': 117,\n 'known': 117,\n 'grain': 117,\n 'enough': 117,\n 'milk': 117,\n 'particular': 116,\n 'priority': 116,\n 'returning': 116,\n 'materials': 116,\n 'chad': 116,\n 'ending': 116,\n 'cause': 115,\n 'statement': 115,\n 'loss': 115,\n 'person': 115,\n 'generally': 115,\n 'moderate': 115,\n 'accessing': 115,\n 'ago': 115,\n 'migration': 115,\n 'authority': 115,\n 'point': 115,\n 'functioning': 115,\n 'figures': 115,\n 'plague': 115,\n 'threshold': 114,\n 'mortality': 114,\n 'travel': 114,\n 'strip': 114,\n 'challenge': 114,\n 'african': 114,\n 'lead': 114,\n 'infected': 114,\n 'factors': 114,\n 'announced': 114,\n 'respondents': 114,\n 'pressure': 113,\n 'property': 113,\n 'doctors': 113,\n 'table': 113,\n 'supported': 113,\n 'showed': 112,\n 'km': 112,\n 'sufficient': 112,\n 'financial': 112,\n 'traders': 111,\n 'deterioration': 111,\n 'flour': 111,\n 'insufficient': 111,\n 'poverty': 111,\n 'towns': 111,\n 'search': 111,\n 'little': 111,\n 'sustained': 111,\n 'largely': 111,\n 'common': 111,\n 'reduce': 111,\n 'northeast': 110,\n 'partially': 110,\n 'must': 110,\n 'experience': 110,\n 'jonglei': 110,\n 'damascus': 110,\n 'yobe': 110,\n '&': 110,\n 'abuse': 110,\n 'places': 109,\n 'included': 109,\n 'costs': 109,\n 'reduction': 109,\n 'torture': 109,\n 'deteriorate': 109,\n 'considered': 109,\n 'air': 109,\n 'relatively': 109,\n 'show': 109,\n 'towards': 109,\n 'money': 109,\n 'address': 109,\n 'tonnes': 109,\n 'legal': 108,\n 'equipment': 108,\n 'shows': 108,\n 'meanwhile': 108,\n 'freedom': 108,\n '—': 108,\n 'makeshift': 108,\n 'alone': 108,\n 'citizens': 108,\n 'purchasing': 108,\n 'longer': 107,\n 'documented': 107,\n 'news': 107,\n 'lebanon': 107,\n 'iraq': 107,\n 'saturday': 107,\n 'coast': 107,\n 'leaders': 107,\n 'rising': 106,\n 'incidence': 106,\n 'evacuation': 106,\n 'feeding': 106,\n 'afghanistan': 106,\n 'admitted': 106,\n 'making': 106,\n 'forecast': 106,\n 'set': 106,\n 'problem': 106,\n 'island': 105,\n 'court': 105,\n 'upper': 105,\n 'growing': 104,\n 'improvement': 104,\n 'fews': 104,\n 'disrupted': 104,\n 'c': 104,\n 'treated': 104,\n 'wounded': 104,\n 'male': 104,\n 'consecutive': 103,\n 'drc': 103,\n 'alert': 103,\n 'palestinians': 103,\n 'reasons': 103,\n 'noted': 103,\n 'issue': 103,\n 'planting': 103,\n 'came': 103,\n 'way': 103,\n 'unity': 103,\n 'surveyed': 103,\n 'bahr': 103,\n 'turkana': 102,\n 'minimum': 102,\n 'persist': 102,\n 'threats': 102,\n 'fields': 102,\n 'mental': 102,\n 'territory': 102,\n 'yesterday': 102,\n 'strategies': 102,\n 'armyworm': 102,\n 'targeting': 102,\n 'cut': 101,\n 'earthquake': 101,\n 'therefore': 101,\n 'islamic': 101,\n 'multiple': 101,\n 'direct': 101,\n 'cameroon': 101,\n 'suffer': 101,\n 'destruction': 101,\n 'short': 100,\n 'threat': 100,\n 'commissioner': 100,\n 'nearby': 100,\n 'established': 100,\n 'housing': 100,\n 'crossing': 100,\n 'five-year': 100,\n 'clean': 100,\n 'cooking': 100,\n 'recruitment': 100,\n 'thus': 99,\n 'imported': 99,\n 'constraints': 99,\n 'occupied': 99,\n 'practices': 99,\n 'de': 99,\n 'strong': 99,\n 'adamawa': 99,\n 'condition': 99,\n 'strike': 99,\n 'boko': 98,\n 'rape': 98,\n 'ten': 98,\n 'urgently': 98,\n 'commercial': 97,\n 'flee': 97,\n 'missing': 97,\n 'affect': 97,\n 'commission': 97,\n 'trends': 97,\n 'monthly': 97,\n 'hepatitis': 96,\n 'cover': 96,\n ...}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we do not longer care about the frequency of each word, we can replace the frequency counts with the word index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# map each word to an index\n",
    "dictionary = {word: index for index, word in enumerate(dictionary.keys())}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Batching\n",
    " Using the dictionary, create batches for any given dataset (train/validation/test). Each batch is a two-dimensional matrix of *batch-size* to *max-document-length*, containing the IDs of the words in the corresponding documents. *Batch-size* and *max-document-length* are two hyper-parameters and can be set to any appropriate values (*Batch-size* must be higher than 1 and *max-document-length* at least 50 words). If a document has more than *max-document-length* words, only the first *max-document-length* words should be kept."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_DOCUMENT_LENGTH = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def create_x_batches(df, dictionary, batch_size: int, max_document_length: int):\n",
    "    \"\"\"\n",
    "    Create batches for any given dataset (train/validation/test) - X\n",
    "    :param df: dataframe, pd.DataFrame\n",
    "    :param dictionary: dictionary, dict\n",
    "    :param batch_size: batch size, int\n",
    "    :param max_document_length: max document length, int\n",
    "    :return: batches of inputs, list of np.ndarray of shape (batch_size, max_document_length)\n",
    "    \"\"\"\n",
    "    n_batches = len(df) // batch_size + 1\n",
    "    print(\"Number of batches: \", n_batches)\n",
    "    batches = []\n",
    "    for batch_idx in range(n_batches):\n",
    "        if batch_idx != n_batches - 1:\n",
    "            # standard batch\n",
    "            batch = np.zeros((batch_size, max_document_length), dtype=np.int32)\n",
    "        else:\n",
    "            # last batch - may be smaller than batch_size\n",
    "            batch = np.zeros((len(df) - batch_idx * batch_size, max_document_length), dtype=np.int32)\n",
    "        current_batch_size = batch.shape[0]\n",
    "        for doc_idx in range(current_batch_size):\n",
    "            doc = df.iloc[batch_idx * batch_size + doc_idx]['tokenized_text']\n",
    "            for word_idx in range(min(len(doc), max_document_length)):\n",
    "                word = doc[word_idx]\n",
    "                batch[doc_idx, word_idx] = dictionary.get(word, dictionary['<oov>'])\n",
    "        batches.append(batch)\n",
    "\n",
    "\n",
    "    return batches\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def create_y_batches(df, batch_size: int):\n",
    "    \"\"\"\n",
    "    Create batches for any given dataset (train/validation/test) - y\n",
    "    :param df: dataframe, pd.DataFrame\n",
    "    :param batch_size: batch size, int\n",
    "    :return: batches of labels, np.ndarray of shape (n_batches, batch_size)\n",
    "    \"\"\"\n",
    "    n_batches = len(df) // batch_size + 1\n",
    "    print(\"Number of batches: \", n_batches)\n",
    "    batches = []\n",
    "    for batch_idx in range(n_batches):\n",
    "        if batch_idx != n_batches - 1:\n",
    "            batch = np.zeros((batch_size), dtype=np.int32)\n",
    "        else:\n",
    "            batch = np.zeros((len(df) - batch_idx * batch_size), dtype=np.int32)\n",
    "        current_batch_size = batch.shape[0]\n",
    "        for doc_idx in range(current_batch_size):\n",
    "            batch[doc_idx] = df.iloc[batch_idx * batch_size + doc_idx]['label']\n",
    "        batches.append(batch)\n",
    "    return batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "       sentence_id                                               text  label  \\\n0             5446  In addition to the immediate life-saving inter...      9   \n1             8812  There are approximately 2.6 million people cla...      3   \n2            16709  While aid imports have held up recently, comme...      5   \n3             3526  Heavy rainfalls as well as onrush of water fro...      0   \n4             4928  Based on field reports 9 , the main production...      3   \n...            ...                                                ...    ...   \n12105        12744  The total gap in the number of people who requ...      8   \n12106         9655  A food crisis is looming in the country with t...      0   \n12107         6963  ? Acute watery diarrhoea (AWD) continues to be...      4   \n12108          923  As South India grapples with drought and water...     11   \n12109        15880  Mirroring trends in South Africa, the main sou...      3   \n\n           caption                                       cleaned_text  \\\n0       Protection  in addition to the immediate life-saving inter...   \n1             Food  there are approximately < num >.< num > millio...   \n2       Livelihood  while aid imports have held up recently, comme...   \n3      Agriculture  heavy rainfalls as well as onrush of water fro...   \n4             Food  based on field reports < num > , the main prod...   \n...            ...                                                ...   \n12105    Nutrition  the total gap in the number of people who requ...   \n12106  Agriculture  a food crisis is looming in the country with t...   \n12107       Health  ? acute watery diarrhoea (awd) continues to be...   \n12108         WASH  as south india grapples with drought and water...   \n12109         Food  mirroring trends in south africa, the main sou...   \n\n                                          tokenized_text  \n0      [addition, immediate, life-saving, interventio...  \n1      [approximately, <, num, >, ., <, num, >, milli...  \n2      [aid, imports, held, recently, ,, commercial, ...  \n3      [heavy, rainfalls, well, onrush, water, upstre...  \n4      [based, field, reports, <, num, >, ,, main, pr...  \n...                                                  ...  \n12105  [total, gap, number, people, require, assistan...  \n12106  [food, crisis, looming, country, season, ’, ma...  \n12107  [?, acute, watery, diarrhoea, (, awd, ), conti...  \n12108  [south, india, grapples, drought, water, short...  \n12109  [mirroring, trends, south, africa, ,, main, so...  \n\n[12110 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>caption</th>\n      <th>cleaned_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5446</td>\n      <td>In addition to the immediate life-saving inter...</td>\n      <td>9</td>\n      <td>Protection</td>\n      <td>in addition to the immediate life-saving inter...</td>\n      <td>[addition, immediate, life-saving, interventio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8812</td>\n      <td>There are approximately 2.6 million people cla...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>there are approximately &lt; num &gt;.&lt; num &gt; millio...</td>\n      <td>[approximately, &lt;, num, &gt;, ., &lt;, num, &gt;, milli...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16709</td>\n      <td>While aid imports have held up recently, comme...</td>\n      <td>5</td>\n      <td>Livelihood</td>\n      <td>while aid imports have held up recently, comme...</td>\n      <td>[aid, imports, held, recently, ,, commercial, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3526</td>\n      <td>Heavy rainfalls as well as onrush of water fro...</td>\n      <td>0</td>\n      <td>Agriculture</td>\n      <td>heavy rainfalls as well as onrush of water fro...</td>\n      <td>[heavy, rainfalls, well, onrush, water, upstre...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4928</td>\n      <td>Based on field reports 9 , the main production...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>based on field reports &lt; num &gt; , the main prod...</td>\n      <td>[based, field, reports, &lt;, num, &gt;, ,, main, pr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12105</th>\n      <td>12744</td>\n      <td>The total gap in the number of people who requ...</td>\n      <td>8</td>\n      <td>Nutrition</td>\n      <td>the total gap in the number of people who requ...</td>\n      <td>[total, gap, number, people, require, assistan...</td>\n    </tr>\n    <tr>\n      <th>12106</th>\n      <td>9655</td>\n      <td>A food crisis is looming in the country with t...</td>\n      <td>0</td>\n      <td>Agriculture</td>\n      <td>a food crisis is looming in the country with t...</td>\n      <td>[food, crisis, looming, country, season, ’, ma...</td>\n    </tr>\n    <tr>\n      <th>12107</th>\n      <td>6963</td>\n      <td>? Acute watery diarrhoea (AWD) continues to be...</td>\n      <td>4</td>\n      <td>Health</td>\n      <td>? acute watery diarrhoea (awd) continues to be...</td>\n      <td>[?, acute, watery, diarrhoea, (, awd, ), conti...</td>\n    </tr>\n    <tr>\n      <th>12108</th>\n      <td>923</td>\n      <td>As South India grapples with drought and water...</td>\n      <td>11</td>\n      <td>WASH</td>\n      <td>as south india grapples with drought and water...</td>\n      <td>[south, india, grapples, drought, water, short...</td>\n    </tr>\n    <tr>\n      <th>12109</th>\n      <td>15880</td>\n      <td>Mirroring trends in South Africa, the main sou...</td>\n      <td>3</td>\n      <td>Food</td>\n      <td>mirroring trends in south africa, the main sou...</td>\n      <td>[mirroring, trends, south, africa, ,, main, so...</td>\n    </tr>\n  </tbody>\n</table>\n<p>12110 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  379\n",
      "Number of batches:  379\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n"
     ]
    }
   ],
   "source": [
    "batches = {}\n",
    "for name, df in zip(['train', 'val', 'test'], [train_df, val_df, test_df]):\n",
    "    batches[name] = {}\n",
    "    batches[name]['x'] = create_x_batches(df, dictionary, BATCH_SIZE, MAX_DOCUMENT_LENGTH)\n",
    "    batches[name]['y'] = create_y_batches(df, BATCH_SIZE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "379"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches['train']['x'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "379"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches['train']['y'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(32, 100)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(32,)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(14, 100)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(14,)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 297,  719, 1335, ...,    0,    0,    0],\n       [ 286,    1,    3, ...,  371,    4,  732],\n       [ 187,  629,  532, ...,    0,    0,    0],\n       ...,\n       [  18,  540,   23, ...,    0,    0,    0],\n       [1709,  125,  114, ...,    0,    0,    0],\n       [ 104,    1,    3, ...,    0,    0,    0]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 9,  3,  5,  0,  3,  9,  9,  1,  4,  4,  9,  3,  8,  9,  4,  9,  9,\n        3,  9,  2,  1, 10,  3,  5,  3,  4,  3,  9,  3, 11,  7, 10])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 231,  126,    1, ...,    0,    0,    0],\n       [ 270,   69, 3517, ...,    5,  319, 1737],\n       [ 205,    1,    3, ...,    1,    3,    2],\n       ...,\n       [  72,   60,  725, ...,    0,    0,    0],\n       [  55, 2010, 8246, ...,    0,    0,    0],\n       [8246,  996,   55, ...,    0,    0,    0]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 4, 11,  4,  3,  3,  4,  9,  8,  4,  8,  0,  4, 11,  3])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word embedding lookup\n",
    " Using `torch.nn.Embedding`, create a lookup for the embeddings of all the words in the dictionary. The lookup is in fact a matrix, which maps the ID of each word to the corresponding word vector. Similar to Assignment 2, use the pre-trained vectors of a word embedding model (like word2vec or GloVe) to initialize the word embeddings of the lookup. Keep in mind that the embeddings of the words in the lookup should be matched with the correct vector in the pretrained word embedding. If the vector of a word in the lookup does not exist in the pretrained word embeddings, the corresponding vector should be initialized randomly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load pre-trained word embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# use gensim to load the word embedding model (GloVe)\n",
    "\n",
    "# Download the GloVe model from https://nlp.stanford.edu/projects/glove/\n",
    "# and unzip it in the /data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncomment this!!! \n"
     ]
    }
   ],
   "source": [
    "print(\"Uncomment this!!! \")\n",
    "\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip glove.6B.zip -d data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import gensim.scripts.glove2word2vec as glove2word2vec\n",
    "# glove_model = glove2word2vec.glove2word2vec('data/glove.6B.300d.txt', 'data/glove.6B.300d.word2vec.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# load the GloVe model\n",
    "glove_model = gensim.models.KeyedVectors.load_word2vec_format('data/glove.6B.300d.word2vec.txt', binary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create word embedding lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "{',': 0,\n '<': 1,\n '>': 2,\n 'num': 3,\n '.': 4,\n ')': 5,\n '(': 6,\n 'cases': 7,\n 'food': 8,\n '%': 9,\n 'people': 10,\n 'reported': 11,\n '’': 12,\n 'children': 13,\n 'areas': 14,\n 'water': 15,\n 'health': 16,\n 'said': 17,\n 'access': 18,\n 'including': 19,\n 'per': 20,\n 'also': 21,\n 'percent': 22,\n ':': 23,\n 'due': 24,\n 'affected': 25,\n 'since': 26,\n 'deaths': 27,\n 'number': 28,\n 'households': 29,\n '“': 30,\n 'total': 31,\n 'country': 32,\n '”': 33,\n 'humanitarian': 34,\n 'two': 35,\n 'security': 36,\n 'week': 37,\n 'million': 38,\n 'one': 39,\n 'prices': 40,\n 'state': 41,\n 'new': 42,\n 'government': 43,\n 'cent': 44,\n 'refugees': 45,\n 'year': 46,\n '-': 47,\n 'displaced': 48,\n 'assistance': 49,\n 'according': 50,\n 'cholera': 51,\n 'phase': 52,\n 'need': 53,\n ';': 54,\n 'south': 55,\n 'suspected': 56,\n 'women': 57,\n 'high': 58,\n 'ipc': 59,\n 'acute': 60,\n 'region': 61,\n 'may': 62,\n 'season': 63,\n 'many': 64,\n 'last': 65,\n 'outbreak': 66,\n 'area': 67,\n 'population': 68,\n 'three': 69,\n 'services': 70,\n 'situation': 71,\n '?': 72,\n 'emergency': 73,\n 'malnutrition': 74,\n 'families': 75,\n 'idps': 76,\n 'january': 77,\n 'local': 78,\n 'average': 79,\n '–': 80,\n 'increased': 81,\n 'poor': 82,\n 'confirmed': 83,\n 'insecurity': 84,\n 'increase': 85,\n 'case': 86,\n 'march': 87,\n 'lack': 88,\n 'city': 89,\n 'crisis': 90,\n 'across': 91,\n 'expected': 92,\n 'years': 93,\n 'risk': 94,\n 'needs': 95,\n 'facilities': 96,\n 'among': 97,\n 'least': 98,\n 'schools': 99,\n 'support': 100,\n 'camps': 101,\n 'school': 102,\n 'conflict': 103,\n 'estimated': 104,\n 'however': 105,\n 'production': 106,\n 'conditions': 107,\n 'compared': 108,\n 'medical': 109,\n 'february': 110,\n 'five': 111,\n 'communities': 112,\n 'levels': 113,\n 'national': 114,\n 'april': 115,\n 'months': 116,\n 'remain': 117,\n 'violence': 118,\n 'continue': 119,\n 'camp': 120,\n 'education': 121,\n 'likely': 122,\n 'authorities': 123,\n 'sudan': 124,\n \"'s\": 125,\n '•': 126,\n 'response': 127,\n 'period': 128,\n 'rate': 129,\n 'well': 130,\n 'still': 131,\n 'limited': 132,\n 'human': 133,\n 'armed': 134,\n 'protection': 135,\n 'rights': 136,\n 'june': 137,\n 'care': 138,\n 'central': 139,\n 'october': 140,\n 'severe': 141,\n 'december': 142,\n 'regions': 143,\n 'killed': 144,\n 'states': 145,\n 'september': 146,\n 'refugee': 147,\n 'report': 148,\n 'rains': 149,\n 'maize': 150,\n 'sites': 151,\n 'forces': 152,\n 'community': 153,\n 'four': 154,\n 'province': 155,\n 'main': 156,\n 'northern': 157,\n 'livestock': 158,\n 'district': 159,\n 'districts': 160,\n 'east': 161,\n 'hospital': 162,\n 'living': 163,\n \"'\": 164,\n 'groups': 165,\n 'west': 166,\n 'ongoing': 167,\n 'recorded': 168,\n 'north': 169,\n 'first': 170,\n 'following': 171,\n 'civilians': 172,\n 'month': 173,\n 'august': 174,\n 'around': 175,\n 'international': 176,\n 'eastern': 177,\n 'currently': 178,\n 'parts': 179,\n 'reports': 180,\n 'nutrition': 181,\n 'markets': 182,\n 'rainfall': 183,\n 'particularly': 184,\n 'recent': 185,\n 'time': 186,\n 'aid': 187,\n 'remains': 188,\n 'displacement': 189,\n 'town': 190,\n 'result': 191,\n 'july': 192,\n 'early': 193,\n 'al': 194,\n 'disease': 195,\n 'southern': 196,\n 'drought': 197,\n 'several': 198,\n 'partners': 199,\n 'vulnerable': 200,\n 'november': 201,\n 'market': 202,\n 'shelter': 203,\n 'activities': 204,\n 'weeks': 205,\n 'patients': 206,\n 'basic': 207,\n 'continued': 208,\n 'treatment': 209,\n 'idp': 210,\n 'residents': 211,\n 'could': 212,\n 'assessment': 213,\n 'houses': 214,\n 'low': 215,\n 'gaza': 216,\n 'military': 217,\n 'border': 218,\n 'israeli': 219,\n 'ministry': 220,\n 'girls': 221,\n 'supplies': 222,\n 'level': 223,\n 'majority': 224,\n 'death': 225,\n 'already': 226,\n 'attacks': 227,\n 'un': 228,\n 'el': 229,\n 'continues': 230,\n 'measles': 231,\n 'harvest': 232,\n 'six': 233,\n 'days': 234,\n 'forced': 235,\n 'homes': 236,\n 'damaged': 237,\n 'higher': 238,\n 'host': 239,\n 'price': 240,\n 'reportedly': 241,\n 'past': 242,\n 'public': 243,\n 'palestinian': 244,\n 'available': 245,\n 'syrian': 246,\n 'supply': 247,\n 'even': 248,\n 'land': 249,\n 'day': 250,\n 'shelters': 251,\n 'county': 252,\n 'group': 253,\n 'agricultural': 254,\n 'within': 255,\n 'fever': 256,\n 'villages': 257,\n 'previous': 258,\n 'told': 259,\n 'increasing': 260,\n 'destroyed': 261,\n 'end': 262,\n 'household': 263,\n 'current': 264,\n 'without': 265,\n 'child': 266,\n 'crops': 267,\n 'face': 268,\n 'died': 269,\n 'nearly': 270,\n 'age': 271,\n 'counties': 272,\n 'injured': 273,\n 'sources': 274,\n 'would': 275,\n 'especially': 276,\n 'major': 277,\n 'return': 278,\n 'police': 279,\n 'availability': 280,\n 'reporting': 281,\n 'severely': 282,\n 'unhcr': 283,\n 'cfr': 284,\n 'syria': 285,\n 'approximately': 286,\n 'significant': 287,\n 'safe': 288,\n 'sanitation': 289,\n 'wash': 290,\n 'beginning': 291,\n 'critical': 292,\n 'western': 293,\n 'received': 294,\n 'heavy': 295,\n 'rates': 296,\n 'addition': 297,\n 'half': 298,\n 'additional': 299,\n 'caused': 300,\n 'less': 301,\n 'provide': 302,\n 'river': 303,\n 'members': 304,\n 'despite': 305,\n 'crop': 306,\n 'rural': 307,\n 'diseases': 308,\n 'concern': 309,\n 'world': 310,\n 'malaria': 311,\n 'highest': 312,\n 'near': 313,\n 'lower': 314,\n 'work': 315,\n 'impact': 316,\n 'men': 317,\n 'control': 318,\n 'use': 319,\n 'found': 320,\n 'others': 321,\n 'primary': 322,\n 'unicef': 323,\n 'identified': 324,\n 'fuel': 325,\n 'large': 326,\n 'capacity': 327,\n 'far': 328,\n 'provinces': 329,\n 'locations': 330,\n 'overall': 331,\n 'almost': 332,\n 'management': 333,\n 'provided': 334,\n 'system': 335,\n 'capital': 336,\n 'settlements': 337,\n 'outcomes': 338,\n 'family': 339,\n 'damage': 340,\n 'although': 341,\n 'populations': 342,\n 'persons': 343,\n 'figure': 344,\n 'centre': 345,\n 'insecure': 346,\n 'income': 347,\n 'dengue': 348,\n 'part': 349,\n '/': 350,\n 'facing': 351,\n 'attack': 352,\n 'rice': 353,\n 'needed': 354,\n 'nigeria': 355,\n 'yemen': 356,\n 'centres': 357,\n 'workers': 358,\n 'migrants': 359,\n 'fatality': 360,\n 'source': 361,\n 'information': 362,\n 'lean': 363,\n 'thousands': 364,\n 'livelihood': 365,\n 'darfur': 366,\n 'fighting': 367,\n 'laboratory': 368,\n 'reduced': 369,\n 'left': 370,\n 'consumption': 371,\n 'resources': 372,\n 'official': 373,\n 'somali': 374,\n 'seven': 375,\n 'rohingya': 376,\n 'normal': 377,\n 'used': 378,\n 'drinking': 379,\n 'wfp': 380,\n 'sam': 381,\n 'spread': 382,\n 'borno': 383,\n 'positive': 384,\n 'improved': 385,\n 'movement': 386,\n 'livelihoods': 387,\n 'floods': 388,\n 'registered': 389,\n 'conducted': 390,\n 'remained': 391,\n 'staple': 392,\n 'somalia': 393,\n 'power': 394,\n 'village': 395,\n 'along': 396,\n 'late': 397,\n 'farmers': 398,\n 'sexual': 399,\n 'civilian': 400,\n 'sector': 401,\n 'incidents': 402,\n 'th': 403,\n 'data': 404,\n 'countries': 405,\n 'hygiene': 406,\n 'casualties': 407,\n 'significantly': 408,\n 'operations': 409,\n 'second': 410,\n 'governorates': 411,\n 'army': 412,\n 'organization': 413,\n 'kenya': 414,\n 'bank': 415,\n 'working': 416,\n 'staff': 417,\n 'place': 418,\n 'nile': 419,\n 'led': 420,\n 'respectively': 421,\n 'another': 422,\n '$': 423,\n 'live': 424,\n 'serious': 425,\n 'harvests': 426,\n 'mainly': 427,\n 'started': 428,\n 'says': 429,\n 'opportunities': 430,\n 'concerns': 431,\n 'gam': 432,\n 'pastoral': 433,\n 'start': 434,\n 'relief': 435,\n 'located': 436,\n 'flooding': 437,\n 'cereal': 438,\n 'outbreaks': 439,\n 'hospitals': 440,\n 'urgent': 441,\n 'closed': 442,\n 'officials': 443,\n 'include': 444,\n 'infrastructure': 445,\n 'agency': 446,\n 'stressed': 447,\n 'often': 448,\n 'ethiopia': 449,\n 'rainy': 450,\n 'service': 451,\n 'dry': 452,\n 'governorate': 453,\n 'reached': 454,\n 'open': 455,\n 'based': 456,\n 'distribution': 457,\n 'red': 458,\n 'close': 459,\n 'able': 460,\n 'affecting': 461,\n 'resulted': 462,\n 'media': 463,\n 'targeted': 464,\n 'numbers': 465,\n 'home': 466,\n 'given': 467,\n 'zone': 468,\n 'individuals': 469,\n 'made': 470,\n 'hit': 471,\n 'arrivals': 472,\n 'myanmar': 473,\n 'site': 474,\n 'civil': 475,\n 'long': 476,\n 'outside': 477,\n 'teachers': 478,\n 'sudanese': 479,\n 'improve': 480,\n 'fled': 481,\n 'stocks': 482,\n 'key': 483,\n 'eight': 484,\n 'general': 485,\n 'efforts': 486,\n 'decline': 487,\n 'reach': 488,\n 'prevalence': 489,\n 'related': 490,\n 'monday': 491,\n 'items': 492,\n 'united': 493,\n 'republic': 494,\n 'risks': 495,\n 'meet': 496,\n 'awd': 497,\n 'zones': 498,\n 'malnourished': 499,\n 'actors': 500,\n 'require': 501,\n 'yet': 502,\n 'department': 503,\n 'us': 504,\n 'famine': 505,\n 'samples': 506,\n 'challenges': 507,\n 'students': 508,\n 'shortage': 509,\n 'global': 510,\n 'aged': 511,\n 'war': 512,\n 'using': 513,\n 'urban': 514,\n 'cluster': 515,\n 'trend': 516,\n 'decrease': 517,\n 'lives': 518,\n 'detention': 519,\n 'seasonal': 520,\n 'today': 521,\n 'results': 522,\n 'greater': 523,\n 'back': 524,\n 'economic': 525,\n 'violations': 526,\n 'agriculture': 527,\n 'arrived': 528,\n 'adequate': 529,\n 'ghouta': 530,\n 'radio': 531,\n 'held': 532,\n 'wheat': 533,\n 'electricity': 534,\n 'recently': 535,\n 'shortages': 536,\n 'resulting': 537,\n 'mostly': 538,\n 'plan': 539,\n 'latrines': 540,\n 'clashes': 541,\n 'road': 542,\n 'lost': 543,\n 'followed': 544,\n 'regional': 545,\n 'social': 546,\n 'cumulative': 547,\n 'healthcare': 548,\n 'suffering': 549,\n 'like': 550,\n 'development': 551,\n 'campaign': 552,\n 'transmission': 553,\n 'much': 554,\n 'throughout': 555,\n '‘': 556,\n 'negative': 557,\n 'rise': 558,\n 'hundreds': 559,\n 'restrictions': 560,\n 'returnees': 561,\n 'essential': 562,\n 'nine': 563,\n 'fire': 564,\n 'decreased': 565,\n 'minister': 566,\n 'funding': 567,\n 'law': 568,\n 'ensure': 569,\n 'taken': 570,\n 'pregnant': 571,\n 'required': 572,\n 'labor': 573,\n 'fall': 574,\n 'internally': 575,\n 'remaining': 576,\n 'sorghum': 577,\n 'observed': 578,\n 'latest': 579,\n 'safety': 580,\n 'order': 581,\n 'analysis': 582,\n 'earlier': 583,\n 'diarrhoea': 584,\n 'roads': 585,\n 'wednesday': 586,\n 'victims': 587,\n 'say': 588,\n 'measures': 589,\n 'occurred': 590,\n 'nations': 591,\n 'leading': 592,\n 'unable': 593,\n 'returned': 594,\n 'daily': 595,\n 'below-average': 596,\n 'injuries': 597,\n 'assessed': 598,\n 'young': 599,\n 'demand': 600,\n 'tuesday': 601,\n 'leaving': 602,\n 'experiencing': 603,\n 'next': 604,\n 'rain': 605,\n 'presence': 606,\n 'quality': 607,\n '[': 608,\n 'centers': 609,\n 'third': 610,\n 'coping': 611,\n 'interventions': 612,\n 'slightly': 613,\n 'increases': 614,\n 'take': 615,\n 'hours': 616,\n 'monitoring': 617,\n 'detained': 618,\n 'agencies': 619,\n 'help': 620,\n 'rapid': 621,\n 'boys': 622,\n 'libya': 623,\n 'niger': 624,\n 'away': 625,\n 'vaccination': 626,\n 'oromia': 627,\n 'trade': 628,\n 'imports': 629,\n 'either': 630,\n 'seen': 631,\n 'africa': 632,\n 'providing': 633,\n 'survey': 634,\n 'date': 635,\n 'cash': 636,\n 'journalists': 637,\n 'cross': 638,\n 'soldiers': 639,\n 'provision': 640,\n 'go': 641,\n 'probable': 642,\n 'possible': 643,\n 'difficult': 644,\n 'flood': 645,\n 'cost': 646,\n 'night': 647,\n ']': 648,\n 'important': 649,\n 'organizations': 650,\n 'temporary': 651,\n 'political': 652,\n 'mosul': 653,\n 'kordofan': 654,\n 'congo': 655,\n 'israel': 656,\n 'indicated': 657,\n 'office': 658,\n 'epidemic': 659,\n 'former': 660,\n 'active': 661,\n 'surveillance': 662,\n 'msf': 663,\n 'diphtheria': 664,\n 'lgas': 665,\n 'different': 666,\n 'experienced': 667,\n 'rakhine': 668,\n 'equatoria': 669,\n 'thursday': 670,\n 'see': 671,\n 'bangladesh': 672,\n 'pasture': 673,\n 'associated': 674,\n 'indicate': 675,\n 'leave': 676,\n 'small': 677,\n 'uganda': 678,\n 'receive': 679,\n 'classified': 680,\n 'arrested': 681,\n 'better': 682,\n 'coming': 683,\n 'medicines': 684,\n 'process': 685,\n 'operation': 686,\n 'buildings': 687,\n 'inside': 688,\n 'sea': 689,\n 'life': 690,\n 'learning': 691,\n 'sunday': 692,\n 'newly': 693,\n 'times': 694,\n 'largest': 695,\n 'friday': 696,\n 'programme': 697,\n 'settlement': 698,\n 'watch': 699,\n 'e': 700,\n 'facility': 701,\n 'disaster': 702,\n 'quarter': 703,\n 'carried': 704,\n 'commodities': 705,\n 'gaps': 706,\n 'make': 707,\n 'though': 708,\n 'opposition': 709,\n 'began': 710,\n 'impacted': 711,\n 'stable': 712,\n 'widespread': 713,\n 'become': 714,\n 'every': 715,\n 'prevent': 716,\n 'minimal': 717,\n 'good': 718,\n 'immediate': 719,\n 'center': 720,\n 'juba': 721,\n 'cattle': 722,\n 'tested': 723,\n 'move': 724,\n 'watery': 725,\n 'body': 726,\n 'added': 727,\n 'head': 728,\n 'influx': 729,\n 'building': 730,\n 'structures': 731,\n 'absence': 732,\n 'issues': 733,\n 'released': 734,\n 'net': 735,\n 'chronic': 736,\n 'inadequate': 737,\n 'declined': 738,\n 'causing': 739,\n 'systems': 740,\n 'president': 741,\n 'oil': 742,\n 'put': 743,\n 'ground': 744,\n 'jerusalem': 745,\n 'coordination': 746,\n 'turkey': 747,\n 'fear': 748,\n 'old': 749,\n 'private': 750,\n 'team': 751,\n 'coverage': 752,\n 'white': 753,\n 'council': 754,\n 'wau': 755,\n 'issued': 756,\n 'extremely': 757,\n 'teams': 758,\n 'female': 759,\n 'projected': 760,\n 'virus': 761,\n 'iom': 762,\n 'force': 763,\n 'attacked': 764,\n 'various': 765,\n 'lassa': 766,\n 'get': 767,\n 'action': 768,\n 'director': 769,\n 'neighbouring': 770,\n 'status': 771,\n 'committee': 772,\n 'meningitis': 773,\n 'foods': 774,\n 'asylum': 775,\n 'line': 776,\n 'killing': 777,\n 'existing': 778,\n 'field': 779,\n 'means': 780,\n 'present': 781,\n '*': 782,\n 'labour': 783,\n 'onset': 784,\n 'physical': 785,\n 'proportion': 786,\n 'infection': 787,\n 'terms': 788,\n 'hunger': 789,\n 'democratic': 790,\n 'scale': 791,\n 'extreme': 792,\n 'declared': 793,\n 'airstrikes': 794,\n 'gap': 795,\n 'explosive': 796,\n 'car': 797,\n 'dead': 798,\n 'similar': 799,\n 'mission': 800,\n 'secondary': 801,\n 'estimates': 802,\n 'domestic': 803,\n 'points': 804,\n 'burundi': 805,\n 'took': 806,\n 'construction': 807,\n 'potential': 808,\n 'weather': 809,\n 'gas': 810,\n 'receiving': 811,\n 'aleppo': 812,\n 'worst': 813,\n 'delivery': 814,\n 'known': 815,\n 'grain': 816,\n 'enough': 817,\n 'milk': 818,\n 'particular': 819,\n 'priority': 820,\n 'returning': 821,\n 'materials': 822,\n 'chad': 823,\n 'ending': 824,\n 'cause': 825,\n 'statement': 826,\n 'loss': 827,\n 'person': 828,\n 'generally': 829,\n 'moderate': 830,\n 'accessing': 831,\n 'ago': 832,\n 'migration': 833,\n 'authority': 834,\n 'point': 835,\n 'functioning': 836,\n 'figures': 837,\n 'plague': 838,\n 'threshold': 839,\n 'mortality': 840,\n 'travel': 841,\n 'strip': 842,\n 'challenge': 843,\n 'african': 844,\n 'lead': 845,\n 'infected': 846,\n 'factors': 847,\n 'announced': 848,\n 'respondents': 849,\n 'pressure': 850,\n 'property': 851,\n 'doctors': 852,\n 'table': 853,\n 'supported': 854,\n 'showed': 855,\n 'km': 856,\n 'sufficient': 857,\n 'financial': 858,\n 'traders': 859,\n 'deterioration': 860,\n 'flour': 861,\n 'insufficient': 862,\n 'poverty': 863,\n 'towns': 864,\n 'search': 865,\n 'little': 866,\n 'sustained': 867,\n 'largely': 868,\n 'common': 869,\n 'reduce': 870,\n 'northeast': 871,\n 'partially': 872,\n 'must': 873,\n 'experience': 874,\n 'jonglei': 875,\n 'damascus': 876,\n 'yobe': 877,\n '&': 878,\n 'abuse': 879,\n 'places': 880,\n 'included': 881,\n 'costs': 882,\n 'reduction': 883,\n 'torture': 884,\n 'deteriorate': 885,\n 'considered': 886,\n 'air': 887,\n 'relatively': 888,\n 'show': 889,\n 'towards': 890,\n 'money': 891,\n 'address': 892,\n 'tonnes': 893,\n 'legal': 894,\n 'equipment': 895,\n 'shows': 896,\n 'meanwhile': 897,\n 'freedom': 898,\n '—': 899,\n 'makeshift': 900,\n 'alone': 901,\n 'citizens': 902,\n 'purchasing': 903,\n 'longer': 904,\n 'documented': 905,\n 'news': 906,\n 'lebanon': 907,\n 'iraq': 908,\n 'saturday': 909,\n 'coast': 910,\n 'leaders': 911,\n 'rising': 912,\n 'incidence': 913,\n 'evacuation': 914,\n 'feeding': 915,\n 'afghanistan': 916,\n 'admitted': 917,\n 'making': 918,\n 'forecast': 919,\n 'set': 920,\n 'problem': 921,\n 'island': 922,\n 'court': 923,\n 'upper': 924,\n 'growing': 925,\n 'improvement': 926,\n 'fews': 927,\n 'disrupted': 928,\n 'c': 929,\n 'treated': 930,\n 'wounded': 931,\n 'male': 932,\n 'consecutive': 933,\n 'drc': 934,\n 'alert': 935,\n 'palestinians': 936,\n 'reasons': 937,\n 'noted': 938,\n 'issue': 939,\n 'planting': 940,\n 'came': 941,\n 'way': 942,\n 'unity': 943,\n 'surveyed': 944,\n 'bahr': 945,\n 'turkana': 946,\n 'minimum': 947,\n 'persist': 948,\n 'threats': 949,\n 'fields': 950,\n 'mental': 951,\n 'territory': 952,\n 'yesterday': 953,\n 'strategies': 954,\n 'armyworm': 955,\n 'targeting': 956,\n 'cut': 957,\n 'earthquake': 958,\n 'therefore': 959,\n 'islamic': 960,\n 'multiple': 961,\n 'direct': 962,\n 'cameroon': 963,\n 'suffer': 964,\n 'destruction': 965,\n 'short': 966,\n 'threat': 967,\n 'commissioner': 968,\n 'nearby': 969,\n 'established': 970,\n 'housing': 971,\n 'crossing': 972,\n 'five-year': 973,\n 'clean': 974,\n 'cooking': 975,\n 'recruitment': 976,\n 'thus': 977,\n 'imported': 978,\n 'constraints': 979,\n 'occupied': 980,\n 'practices': 981,\n 'de': 982,\n 'strong': 983,\n 'adamawa': 984,\n 'condition': 985,\n 'strike': 986,\n 'boko': 987,\n 'rape': 988,\n 'ten': 989,\n 'urgently': 990,\n 'commercial': 991,\n 'flee': 992,\n 'missing': 993,\n 'affect': 994,\n 'commission': 995,\n 'trends': 996,\n 'monthly': 997,\n 'hepatitis': 998,\n 'cover': 999,\n ...}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class WordEmbeddingLookup(nn.Module):\n",
    "    \"\"\"\n",
    "    Create word embedding lookup\n",
    "    \"\"\"\n",
    "    def __init__(self, dictionary, pretrained_embeddings, embedding_dim: int):\n",
    "        \"\"\"\n",
    "        :param dictionary: dictionary, dict\n",
    "        :param pretrained_embeddings: pretrained embeddings, gensim.models.keyedvectors.Word2VecKeyedVectors\n",
    "        :param embedding_dim: embedding dimension, int\n",
    "        \"\"\"\n",
    "        super(WordEmbeddingLookup, self).__init__()\n",
    "        self.dictionary = dictionary\n",
    "        self.pretrained_embeddings = pretrained_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lookup = nn.Embedding(\n",
    "            num_embeddings=len(dictionary),\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.lookup.weight.data.copy_(self._init_weights())\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights of the lookup\n",
    "        :return: weights, torch.Tensor of shape (len(dictionary), embedding_dim)\n",
    "        \"\"\"\n",
    "        weights = torch.zeros(len(self.dictionary), self.embedding_dim)\n",
    "        # 8247 x 300\n",
    "        for idx, word in enumerate(self.dictionary):\n",
    "            try:\n",
    "                weights[idx] = torch.from_numpy(self.pretrained_embeddings[word])\n",
    "            except KeyError:\n",
    "                weights[idx] = torch.randn(self.embedding_dim)\n",
    "        return weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        :param x: input, torch.Tensor of shape (batch_size, max_document_length)\n",
    "        :return: output, torch.Tensor of shape (batch_size, max_document_length, embedding_dim)\n",
    "        \"\"\"\n",
    "        return self.lookup(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\AppData\\Local\\Temp\\ipykernel_27456\\3647153730.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  weights[idx] = torch.from_numpy(self.pretrained_embeddings[word])\n"
     ]
    }
   ],
   "source": [
    "lookup = WordEmbeddingLookup(dictionary, glove_model, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 300])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor([0])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.5539e-01, -2.5723e-01,  1.3169e-01, -4.2688e-02,  2.1817e-01,\n         -2.2702e-02, -1.7854e-01,  1.0756e-01,  5.8936e-02, -1.3854e+00,\n          5.8509e-01,  3.6501e-02, -1.9846e-01,  1.9613e-01,  4.0929e-01,\n          1.5702e-01, -1.5305e-01,  5.0447e-02,  3.0045e-01, -1.1295e-01,\n         -1.7043e-02,  1.8593e-01,  1.9982e-01,  2.0053e-01, -6.3141e-01,\n         -1.2622e-01,  2.9510e-01, -2.6282e-01, -1.5831e-01,  1.2383e-03,\n          1.1784e-02,  5.8758e-01, -1.5914e-01,  2.7731e-01, -8.2343e-01,\n         -2.1134e-01,  1.3414e-02,  1.9637e-01, -4.1470e-01,  1.0276e-03,\n          1.3422e-01, -1.4205e-01,  5.1545e-02,  3.4993e-01, -2.9868e-01,\n         -3.2090e-01,  1.9566e-01,  4.7886e-01,  1.0744e-01,  1.0004e-02,\n          1.8503e-01,  8.0694e-02,  2.0739e-01, -9.7365e-02, -3.9448e-02,\n          2.0151e-02, -1.7378e-01,  2.5679e-01,  2.4198e-01, -3.5100e-01,\n          1.8759e-01,  6.3857e-03,  1.8395e-01, -1.3929e-01,  8.1855e-03,\n         -6.3109e-01,  2.9832e-01,  3.1731e-01,  1.3022e-01, -3.2284e-01,\n         -5.0343e-02, -1.1400e-01,  1.2097e-01,  1.4687e-01, -3.3244e-01,\n         -5.5789e-02, -5.8490e-02,  2.7551e-01, -4.3855e-02,  3.9664e-02,\n          1.5162e-01, -8.6627e-02,  6.7729e-02,  2.3146e-01,  1.5351e-02,\n         -1.5142e-01, -3.1975e-02,  4.5181e-01, -6.8806e-02, -7.7058e-02,\n          5.5193e-02,  5.4596e-02, -2.4708e-01,  3.1113e-02, -1.2826e-01,\n          1.2782e-01, -4.6708e-01, -2.6264e-02,  1.0387e-02, -3.3174e-01,\n          1.7277e-01, -2.6894e-01,  2.0467e-01, -1.6181e-01, -4.1519e-02,\n         -1.4878e-02,  1.0279e-01,  1.8868e-01, -2.3396e-01, -1.8436e-02,\n         -1.4747e-01, -3.2685e-01, -2.2055e-02, -5.4000e-02,  1.6264e-01,\n          2.7095e-01, -2.2792e-01, -7.7006e-03,  1.1206e-01, -3.9787e-02,\n         -1.1906e-01,  2.1773e-02,  5.5280e-02, -1.3318e-01, -5.6867e-02,\n          8.3040e-03, -2.7021e-02,  2.3447e-01,  8.6864e-02,  1.2009e-01,\n         -3.0726e-01,  2.4735e-03,  2.9041e-01, -4.4887e-02,  1.2297e-01,\n          1.3077e-01,  9.0807e-02, -3.9141e-01,  8.0546e-02,  1.8724e-01,\n         -9.7481e-02,  1.0397e-01,  1.1492e-01,  1.7775e-01, -1.8167e-01,\n          2.4652e-01,  2.0136e-01, -2.3395e-01, -3.5018e-01, -1.4061e-01,\n          1.7091e-01, -9.5465e-02, -1.0962e-01, -9.8360e-02,  1.5344e-01,\n          8.8680e-02, -2.2048e-01, -1.3803e-01, -1.1288e-01, -8.5340e-02,\n          7.2735e-02, -1.2732e-01, -1.9640e-01, -1.0586e-01,  2.0616e-03,\n          1.3496e-01,  5.8912e-02, -4.3979e-02, -9.1375e-02,  2.4408e-01,\n          1.6872e-01,  2.4297e-01, -4.3983e-01,  4.7089e-01, -1.8595e-02,\n          1.6146e-01,  1.9828e-01, -1.7237e-01, -2.6998e-03,  5.2097e-01,\n         -8.0197e-02,  4.3324e-01, -6.6261e-02,  4.3240e-02,  8.4954e-02,\n         -1.4836e-01, -4.1936e-01,  1.5988e-01, -1.8411e-01,  1.3210e-01,\n          2.7476e-01,  2.7279e-01, -1.3465e-01, -9.1238e-02, -3.2523e-01,\n          2.7936e-01,  2.3296e-02, -3.3472e-01,  1.6878e-02, -5.5544e-02,\n          9.2915e-01, -3.3914e-01, -1.4791e-01,  1.7301e-02,  1.8272e-01,\n          3.5108e-01, -1.1438e-01,  1.3228e-01, -2.1064e-02, -2.7453e-01,\n         -1.0081e-01, -4.6296e-02,  2.1689e-01, -5.6319e-02,  1.4651e-01,\n         -2.3536e-02,  6.8026e-02, -4.5453e-02, -2.3851e-01, -3.3868e-01,\n          3.1396e-01, -3.1914e-02, -1.9217e-02,  1.8715e-03, -1.3328e-01,\n          7.0148e-02, -3.9761e-02,  7.0801e-02,  1.8422e-03, -1.2646e-01,\n          2.8675e-02, -9.5728e-02,  2.6673e-01, -3.5536e-01,  1.5286e-01,\n          6.4565e-02,  1.2647e-01,  2.3397e-01, -4.6058e-02,  1.3519e-01,\n         -1.4549e-01,  2.3031e-01,  4.2066e-01,  1.6267e-01, -1.6541e-01,\n         -2.0155e-03,  8.0653e-02, -3.0025e-01, -7.6014e-02,  7.0612e-02,\n          3.1570e-01,  5.3520e-02, -1.0721e-01, -1.3660e-01,  3.2214e-01,\n          2.0040e-01,  1.1609e-01, -2.2501e-01,  1.2155e-01, -1.0851e-01,\n         -6.3187e-02, -2.4553e-01, -5.9751e-02,  6.8787e-02, -1.1627e-01,\n         -8.3402e-03,  5.2044e-03, -2.0159e-01, -2.3663e-02,  1.7562e-01,\n         -3.1475e-01, -1.1162e-01, -1.2492e-01,  1.0949e-01, -2.6913e-01,\n          3.4893e-01, -1.6997e+00, -2.4470e-01,  3.0292e-01,  5.6720e-02,\n         -3.1737e-01,  8.3612e-02,  9.5949e-02, -1.7590e-01,  1.0235e-01,\n          3.6808e-01, -3.4380e-01,  2.0607e-01,  1.9135e-01,  1.0992e-01,\n          7.5968e-02, -1.4359e-02, -7.3794e-02,  2.2176e-01,  1.4652e-01,\n          5.6686e-01,  5.3307e-02, -2.3290e-01, -1.2226e-01,  3.5499e-01]],\n       grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor([0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 300])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor([0, 1, 3, 4, 5])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n        [ 0.0781,  0.1256,  0.4092,  ..., -0.5402,  0.0186,  0.1694],\n        [-0.2471,  0.1417,  0.3834,  ...,  0.1208, -0.0695,  0.2728],\n        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n        [-0.1388, -0.2495, -0.1390,  ..., -0.5921,  0.3364, -0.3376]],\n       grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor([0, 1, 3, 4, 5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 100, 300])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor(batches['train']['x'][0])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.3065,  0.1035,  0.1314,  ..., -0.2260, -0.1216, -0.1998],\n         [ 0.2865, -0.1274,  0.2993,  ...,  0.0082, -0.1743,  0.0679],\n         [-0.0869, -0.2978,  0.5271,  ..., -0.1748,  0.3437, -0.3702],\n         ...,\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550]],\n\n        [[-0.8402,  0.1228, -0.0439,  ...,  0.3091,  0.2616, -0.6601],\n         [ 0.0781,  0.1256,  0.4092,  ..., -0.5402,  0.0186,  0.1694],\n         [-0.2471,  0.1417,  0.3834,  ...,  0.1208, -0.0695,  0.2728],\n         ...,\n         [ 0.1376,  0.8267, -0.0110,  ...,  0.0446,  0.0998, -0.6314],\n         [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n         [ 0.0354, -0.0639,  0.0024,  ..., -0.3730, -0.1845,  0.1761]],\n\n        [[-0.0900, -0.7406, -0.1571,  ...,  0.1088, -0.3891,  0.1672],\n         [ 0.4358,  0.2319, -0.2250,  ..., -0.5412,  0.5101, -0.2823],\n         [-0.3396, -0.0727, -0.1596,  ..., -0.4824, -0.3472,  0.0435],\n         ...,\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550]],\n\n        ...,\n\n        [[-0.3458, -0.4930,  0.1680,  ...,  0.0419, -0.2587, -0.2274],\n         [-0.6812,  0.2399, -0.1369,  ..., -0.1962,  0.7529,  0.3970],\n         [ 0.0963, -0.2143,  0.1403,  ..., -0.3957, -0.1794,  0.5939],\n         ...,\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550]],\n\n        [[ 0.8583,  0.2088,  0.1964,  ..., -0.4205,  0.1143, -0.3841],\n         [-0.0013,  0.3651, -0.0774,  ..., -0.1836, -0.7652,  0.3921],\n         [-0.0666,  0.7397,  0.0369,  ..., -0.0585, -0.2657, -0.2135],\n         ...,\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550]],\n\n        [[-0.5219,  0.7321,  0.1877,  ...,  0.1389,  0.0840, -0.4217],\n         [ 0.0781,  0.1256,  0.4092,  ..., -0.5402,  0.0186,  0.1694],\n         [-0.2471,  0.1417,  0.3834,  ...,  0.1208, -0.0695,  0.2728],\n         ...,\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n         [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550]]],\n       grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor(batches['train']['x'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14, 100, 300])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor(batches['train']['x'][-1])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-3.8775e-01,  4.1099e-01, -2.0687e-02,  ..., -5.0146e-01,\n           3.2521e-01, -5.7759e-01],\n         [ 2.6800e-01,  1.3567e+00,  1.1129e+00,  ...,  3.1996e-01,\n          -1.5623e+00, -3.3304e-02],\n         [ 7.8119e-02,  1.2563e-01,  4.0916e-01,  ..., -5.4024e-01,\n           1.8594e-02,  1.6943e-01],\n         ...,\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01]],\n\n        [[-2.2436e-01,  3.2679e-01,  1.8346e-02,  ..., -2.0585e-01,\n          -4.1200e-01, -3.4145e-01],\n         [-3.7763e-01,  5.0981e-01, -4.4110e-01,  ..., -6.0567e-01,\n          -4.4908e-01, -1.4731e-01],\n         [-5.7449e-02,  8.0789e-02, -1.1824e-01,  ..., -1.1858e-03,\n           2.1189e-01, -2.9694e-01],\n         ...,\n         [-1.3877e-01, -2.4946e-01, -1.3896e-01,  ..., -5.9205e-01,\n           3.3636e-01, -3.3764e-01],\n         [-1.0515e-01,  1.3407e-01,  1.3839e-01,  ..., -4.1949e-01,\n           8.9402e-02,  1.7569e-01],\n         [-1.9073e-01, -1.7206e-01, -5.4401e-01,  ..., -3.1628e-02,\n           7.8345e-02,  2.7092e-01]],\n\n        [[-1.7814e-01,  1.9422e-02, -1.8881e-01,  ..., -4.3968e-01,\n          -4.6828e-01, -8.9665e-02],\n         [ 7.8119e-02,  1.2563e-01,  4.0916e-01,  ..., -5.4024e-01,\n           1.8594e-02,  1.6943e-01],\n         [-2.4710e-01,  1.4174e-01,  3.8344e-01,  ...,  1.2077e-01,\n          -6.9548e-02,  2.7282e-01],\n         ...,\n         [ 7.8119e-02,  1.2563e-01,  4.0916e-01,  ..., -5.4024e-01,\n           1.8594e-02,  1.6943e-01],\n         [-2.4710e-01,  1.4174e-01,  3.8344e-01,  ...,  1.2077e-01,\n          -6.9548e-02,  2.7282e-01],\n         [-1.6601e-01,  1.4081e-01,  4.6603e-01,  ..., -3.5561e-01,\n           7.4174e-01,  4.1375e-01]],\n\n        ...,\n\n        [[-8.3300e-02, -2.0896e-01, -4.3623e-02,  ..., -1.7745e-01,\n           5.5793e-02,  8.0126e-01],\n         [-1.7501e-01,  4.4941e-01, -1.5821e-02,  ..., -1.2013e-01,\n           2.1710e-01, -8.8589e-01],\n         [-5.8517e-04,  8.6176e-02, -6.2549e-02,  ...,  4.1881e-01,\n          -2.5998e-01, -6.3070e-02],\n         ...,\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01]],\n\n        [[-3.9116e-01,  1.5113e-01, -1.8260e-01,  ..., -5.6988e-02,\n           1.4564e-01,  9.1975e-02],\n         [-1.1337e-01, -5.7114e-01,  7.0453e-02,  ..., -3.9104e-01,\n           3.5309e-01, -1.7767e-01],\n         [ 1.5813e+00, -1.6534e+00,  6.0109e-01,  ..., -9.3820e-01,\n          -8.3016e-01,  3.2501e-01],\n         ...,\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01]],\n\n        [[ 1.5813e+00, -1.6534e+00,  6.0109e-01,  ..., -9.3820e-01,\n          -8.3016e-01,  3.2501e-01],\n         [ 1.8015e-01, -6.4859e-02,  4.2917e-01,  ...,  4.5782e-01,\n           6.8569e-02,  4.6032e-02],\n         [-3.9116e-01,  1.5113e-01, -1.8260e-01,  ..., -5.6988e-02,\n           1.4564e-01,  9.1975e-02],\n         ...,\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01],\n         [-2.5539e-01, -2.5723e-01,  1.3169e-01,  ..., -2.3290e-01,\n          -1.2226e-01,  3.5499e-01]]], grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(torch.LongTensor(batches['train']['x'][-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model definition and Forward function\n",
    "Define the class `ClassificationAverageModel` as a PyTorch model. In the initialization procedure, the model receives the word embedding lookup, and includes it in the model as model's parameters. These embeddings parameters should be trainable, meaning that the word vectors get updated during model training. Feel free to add any other parameters to the model, which might be necessary for accomplishing the functionalities explained in the following.\n",
    "\n",
    " The forward function of the model receives a batch of data, and first fetches the corresponding embeddings of the word IDs in the batch using the lookup. Similar to Assignment 2, the embedding of a document is created by calculating the *element-wise mean* of the embeddings of the document's words. Formally, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "<center><div>$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$</div></center>\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document. An important point in the implementation of this formula is that the documents in the batch might have different lengths and therefore each document should be divided by its corresponding $|d|$. Finally, this document embedding is utilized to predict the probability of the output classes, done by applying a linear transformation from the embeddings size to the number of classes, followed by Softmax. The linear transformation also belongs to the model's parameters and will be learned in training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class ClassificationAverageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, lookup, num_classes: int):\n",
    "        \"\"\"\n",
    "        Initialize the model - include the lookup as model's parameters\n",
    "        :param lookup: word embedding lookup, WordEmbeddingLookup\n",
    "        :param num_classes: number of classes, int\n",
    "        \"\"\"\n",
    "        super(ClassificationAverageModel, self).__init__()\n",
    "        self.lookup = lookup\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(300, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass - get lookup of x, calculate the mean of the embeddings of the words in the document,\n",
    "        and apply a linear transformation to the embeddings size to the number of classes followed by Softmax\n",
    "        :param x: input, torch.Tensor of shape (batch_size, max_document_length)\n",
    "        :return: output, torch.Tensor of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # get the embeddings of the word IDs in the batch using the lookup\n",
    "        x = self.lookup(x)\n",
    "        # calculate the *element-wise mean* of the embeddings of the document's words\n",
    "        x = torch.mean(x, dim=1)\n",
    "        # apply a linear transformation from the embeddings size to the number of classes, followed by Softmax\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss Function and optimization\n",
    "The loss between the predicted and the actual classes is calculated using Negative Log Likelihood or Cross Entropy. Update the model's parameters using any appropriate optimization mechanism such as Adam.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "model = ClassificationAverageModel(lookup, np.unique(train_df[\"label\"]).shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "LOSS = \"ce\"\n",
    "if LOSS == \"nll\":\n",
    "    criterion = nn.NLLLoss()\n",
    "else:\n",
    "    # Cross Entropy is the default loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "optim_fn = \"adam\"\n",
    "\n",
    "if optim_fn == \"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "else:\n",
    "    # Adam is the default optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Early Stopping\n",
    "After each epoch, evaluate the model on the *validation set* using accuracy. If the evaluation result (accuracy) improves, save the model as the best performing one so far. If the results are not improving after a certain number of evaluation rounds (set as another hyper-parameter) or if training reaches a certain number of epochs, terminate the training procedure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def do_train(model, criterion, optimizer, batches, epochs: int = 20, patience: int = 3,):\n",
    "    \"\"\"\n",
    "    Train the model for a number of epochs\n",
    "    :param model: model to train, ClassificationAverageModel\n",
    "    :param criterion: loss function, nn.CrossEntropyLoss\n",
    "    :param optimizer: optimization method, optim.Adam\n",
    "    :param batches: batches of data, list of (np.array, np.array)\n",
    "    :param epochs: number of epochs, int\n",
    "    :param patience: number of epochs to wait before early stopping, int\n",
    "    :return: best model, ClassificationAverageModel\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    X_train = batches[\"train\"][\"x\"]\n",
    "    y_train = batches[\"train\"][\"y\"]\n",
    "    X_val = batches[\"val\"][\"x\"]\n",
    "    y_val = batches[\"val\"][\"y\"]\n",
    "    patience_counter = 0\n",
    "    loss = torch.tensor(0.0)\n",
    "\n",
    "    print(\"Start training!\")\n",
    "    print(\"=\" * len(\"Start training!\"))\n",
    "    print(f\"Optimizer: {optim_fn}, Loss: {LOSS}, LR: {LR}\")\n",
    "    print(f\"Epochs: {epochs}, Patience: {patience}\")\n",
    "    print(\"=\" * len(f\"Epochs: {epochs}, Patience: {patience}\"))\n",
    "    print()\n",
    "\n",
    "    # LOOP OVER EPOCHS\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc=\"Epochs\", total=epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        model.train()\n",
    "        # lists of all predictions and labels to calculate accuracy\n",
    "        y_pred_all = []\n",
    "        y_true_all = []\n",
    "        losses = []\n",
    "        for x, y in tqdm(zip(X_train, y_train), desc=\"Training\", total=len(X_train)):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(torch.LongTensor(x))\n",
    "            y_true = torch.LongTensor(y)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # to calculate accuracy\n",
    "            y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "            y_true_all.append(y_true.tolist())\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "        y_true_all = np.concatenate(y_true_all)\n",
    "        acc = accuracy_score(y_true_all, y_pred_all)\n",
    "        print(f\"Train accuracy: {acc}, Train loss: {np.mean(losses)}\")\n",
    "\n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        # lists of all predictions and labels to calculate accuracy\n",
    "        y_pred_all = []\n",
    "        y_true_all = []\n",
    "        for x, y in zip(X_val, y_val):\n",
    "            y_pred = model(torch.LongTensor(x))\n",
    "            y_true = torch.LongTensor(y)\n",
    "            y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "            y_true_all.append(y_true.tolist())\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "        y_true_all = np.concatenate(y_true_all)\n",
    "        acc = accuracy_score(y_true_all, y_pred_all)\n",
    "        print(f\"Validation Accuracy: {acc}\")\n",
    "\n",
    "        # EARLY STOPPING\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model, \"best_model.pt\")\n",
    "            print(\"Best model updated\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "    torch.save(model, \"last_model.pt\")\n",
    "    print(\"Training finished\")\n",
    "    print(\"Best validation accuracy: \", best_acc)\n",
    "    print(\"Best epoch: \", best_epoch)\n",
    "    return best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "===============\n",
      "Optimizer: adam, Loss: ce, LR: 0.001\n",
      "Epochs: 20, Patience: 3\n",
      "=======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09500d7d2ae344c795ac22ec8d0c3a1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f258790e5e92471889c21334ba441326"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.3976878612716763, Train loss: 2.2723898944250824\n",
      "Validation Accuracy: 0.4911402157164869\n",
      "Best model updated\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82cd6450fc1048c2a4181a34b285983a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5526011560693641, Train loss: 2.1160440152427453\n",
      "Validation Accuracy: 0.5697226502311248\n",
      "Best model updated\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea18a093fd194ae2bff9da1e0b9e98d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5827415359207266, Train loss: 2.066937974700827\n",
      "Validation Accuracy: 0.5835901386748844\n",
      "Best model updated\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10ee5ea837ea40298f6dfdbc50d700fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5953757225433526, Train loss: 2.0453213811864326\n",
      "Validation Accuracy: 0.5882126348228043\n",
      "Best model updated\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92d03941e00d4496a6b462ef7a3bbbd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6002477291494632, Train loss: 2.0328615397450793\n",
      "Validation Accuracy: 0.5912942989214176\n",
      "Best model updated\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e8edd7120104c8d8e3786b88be77445"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6166804293971924, Train loss: 2.016833466086979\n",
      "Validation Accuracy: 0.6124807395993837\n",
      "Best model updated\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "220aec540fd549c595f6ee658ba0d13c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6427745664739885, Train loss: 1.9952627612292608\n",
      "Validation Accuracy: 0.6305855161787365\n",
      "Best model updated\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ec609adb2814f058b802020b4b96524"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6728323699421965, Train loss: 1.9700517610383852\n",
      "Validation Accuracy: 0.6587057010785824\n",
      "Best model updated\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3850ece6764440f8bd217e0d54b0df1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7162675474814203, Train loss: 1.9342780415175143\n",
      "Validation Accuracy: 0.7030046224961479\n",
      "Best model updated\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7ce4d9c6cfc4f39bab56014ebe9d9e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.747811725846408, Train loss: 1.9044404646337505\n",
      "Validation Accuracy: 0.7268875192604006\n",
      "Best model updated\n",
      "Epoch: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d39a31b1e42a486da86dc87a1ca90ae9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7658133773740711, Train loss: 1.8851335897923773\n",
      "Validation Accuracy: 0.7411402157164869\n",
      "Best model updated\n",
      "Epoch: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5de3f3bcc164568b36ed092b519720a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7858794384805946, Train loss: 1.8632696999094418\n",
      "Validation Accuracy: 0.7530816640986132\n",
      "Best model updated\n",
      "Epoch: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d823bdf19b0247bcb850809263e2da93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7998348472336911, Train loss: 1.8465798917106084\n",
      "Validation Accuracy: 0.7588597842835131\n",
      "Best model updated\n",
      "Epoch: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b114f407c6d143c3b50d9958b5d905dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8083402146985962, Train loss: 1.8346619646907796\n",
      "Validation Accuracy: 0.762326656394453\n",
      "Best model updated\n",
      "Epoch: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dee97a3016f645618faeee00eeb9300f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8146985962014863, Train loss: 1.8254611545628168\n",
      "Validation Accuracy: 0.7619414483821263\n",
      "Epoch: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cbab6a695ec458f97862234bdd0c22f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8189099917423617, Train loss: 1.81789860467483\n",
      "Validation Accuracy: 0.7630970724191063\n",
      "Best model updated\n",
      "Epoch: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c648fc72a4104b909f30efc385b38813"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8230388109000826, Train loss: 1.8115453521934852\n",
      "Validation Accuracy: 0.7654083204930663\n",
      "Best model updated\n",
      "Epoch: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cff87bb860644bbbf360d6273c02ca1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.826094137076796, Train loss: 1.8062350013954345\n",
      "Validation Accuracy: 0.7661787365177196\n",
      "Best model updated\n",
      "Epoch: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "298ece56e87a4406b55a1967fb4df76b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8284062758051197, Train loss: 1.8017947849937983\n",
      "Validation Accuracy: 0.7673343605546995\n",
      "Best model updated\n",
      "Epoch: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95e0a19aed1847e997d251e7d345b1f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.830635838150289, Train loss: 1.798039391361629\n",
      "Validation Accuracy: 0.7665639445300462\n",
      "Training finished\n",
      "Best validation accuracy:  0.7673343605546995\n",
      "Best epoch:  19\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "DO_TRAIN = True\n",
    "\n",
    "if DO_TRAIN:\n",
    "    best_model = do_train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batches=batches,\n",
    "        epochs=N_EPOCHS,\n",
    "        patience=3,\n",
    "    )\n",
    "else:\n",
    "    best_model = torch.load(\"best_model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Set Evaluation\n",
    "After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def predict(model, input):\n",
    "    \"\"\"\n",
    "    Predict the classes of the test set\n",
    "    :param model: trained model, Classifica*tionAverageModel\n",
    "    :param input: test set, list of np.array\n",
    "    :return: predicted classes, torch.Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_pred_all = []\n",
    "    for x in input:\n",
    "        y_pred = model(torch.LongTensor(x))\n",
    "        y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "    return np.concatenate(y_pred_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "y_pred_test = predict(best_model, batches[\"test\"][\"x\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "assert y_pred_test.shape == (test_df.shape[0],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7714836223506744"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = accuracy_score(test_df[\"label\"], y_pred_test)\n",
    "acc_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reporting\n",
    "During loading and processing the collection, provide sufficient information and examples about the data and the applied processing steps. Report the results of the best performing model on the validation and test set in a table.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sufficient information and examples are provided throughout the notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "y_pred_val = predict(best_model, batches[\"val\"][\"x\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7673343605546995"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_val = accuracy_score(val_df[\"label\"], y_pred_val)\n",
    "acc_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7673343605546995\n",
      "Test accuracy: 0.7714836223506744\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation accuracy: {acc_val}\")\n",
    "print(f\"Test accuracy: {acc_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "   Validation Accuracy  Test Accuracy\n0             0.767334       0.771484",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation Accuracy</th>\n      <th>Test Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.767334</td>\n      <td>0.771484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.DataFrame(\n",
    "    {\n",
    "        \"Validation Accuracy\": [acc_val],\n",
    "        \"Test Accuracy\": [acc_test],\n",
    "    }\n",
    ")\n",
    "report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with BERT (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "    \n",
    "This task aims to conduct the same document classification as Task A, but now by utilizing a pre-trained BERT model. Feel free to reuse any code from the previous task. The implementation of the classifier should cover the points below.\n",
    "\n",
    "**Loading BERT model (2 points):** Use the `transformers` library from `huggingface` to load a (small) pre-trained BERT model. Select a BERT model according to your available resources. The available models can be found [here](https://huggingface.co/models) and [here](https://github.com/google-research/bert).\n",
    "\n",
    "**BERT tokenization (3 points):** For training BERT models, we do not need to create a dictionary anymore, as a BERT model already contains an internal subword dictionary. Following the instruction in `transformers`'s documentation, tokenize the data using the BERT model.  \n",
    "\n",
    "**Model definition and forward function (5 points):** Define the class **`ClassificationBERTModel`** as a PyTorch model. In the initialization procedure, the model receives the loaded BERT model and stores it as the model's parameter. The parameters of the BERT model should be trainable. The forward function of the model receives a batch of data, passes this batch to BERT, and achieves the corresponding document embeddings from the output of BERT. Similar to the previous task, the document embeddings are used for classification by linearly transforming document embeddings to the vectors with the number of classes, followed by applying Softmax.\n",
    "\n",
    "**Training and overall functionality (3 points):** Train the model in a similar fashion to the previous task, namely with the proper loss function, optimization, and early stopping.\n",
    "\n",
    "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
    "\n",
    "**Reporting (1 point):** Report the results of the best performing model on the validation and test set in a table.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading BERT model\n",
    "Use the `transformers` library from `huggingface` to load a (small) pre-trained BERT model. Select a BERT model according to your available resources. The available models can be found [here](https://huggingface.co/models) and [here](https://github.com/google-research/bert).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# use bert tiny\n",
    "MODEL = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "\n",
    "bert_model = BertModel.from_pretrained(MODEL)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL, padding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT tokenization\n",
    "For training BERT models, we do not need to create a dictionary anymore, as a BERT model already contains an internal subword dictionary. Following the instruction in `transformers`'s documentation, tokenize the data using the BERT model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def tokenize_bert(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize the text using the BERT tokenizer\n",
    "    :param text: text to tokenize, str\n",
    "    :param tokenizer: BERT tokenizer, BertTokenizer\n",
    "    :return: tokenized text, list of str\n",
    "    \"\"\"\n",
    "    return tokenizer.tokenize(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  In addition to the immediate life-saving interventions, UNICEF is taking action to protect 200 children who have arrived at the camps in Angola without their families.\n",
      "['in', 'addition', 'to', 'the', 'immediate', 'life', '-', 'saving', 'interventions', ',', 'unicef', 'is', 'taking', 'action', 'to', 'protect', '200', 'children', 'who', 'have', 'arrived', 'at', 'the', 'camps', 'in', 'angola', 'without', 'their', 'families', '.']\n",
      "\n",
      "Original text:  There are approximately 2.6 million people classified in this phase, of which 0.5 million are already in Emergency (IPC Phase 4) but do not meet the threshold of more than 20 percent of the population being in this Phase, for the areas to be classified in Phase 4. The counties classified in Crisis (IPC Phase 3) are Turkana, Marsabit, West Pokot, Samburu, Isiolo and Lamu, as well as parts of Mandera, Wajir, Garissa, Baringo, Laikipia, Kilifi and Kwale. Households in this category are marginally able to meet their minimum food needs but only by more rapidly depleting their assets and thus undermining their food consumption. In the absence of adequate cross-sectoral interventions, more areas and households in these counties are expected to fall into this phase by October 2017.\n",
      "['there', 'are', 'approximately', '2', '.', '6', 'million', 'people', 'classified', 'in', 'this', 'phase', ',', 'of', 'which', '0', '.', '5', 'million', 'are', 'already', 'in', 'emergency', '(', 'ip', '##c', 'phase', '4', ')', 'but', 'do', 'not', 'meet', 'the', 'threshold', 'of', 'more', 'than', '20', 'percent', 'of', 'the', 'population', 'being', 'in', 'this', 'phase', ',', 'for', 'the', 'areas', 'to', 'be', 'classified', 'in', 'phase', '4', '.', 'the', 'counties', 'classified', 'in', 'crisis', '(', 'ip', '##c', 'phase', '3', ')', 'are', 'turk', '##ana', ',', 'mars', '##abi', '##t', ',', 'west', 'po', '##kot', ',', 'sam', '##bu', '##ru', ',', 'is', '##iol', '##o', 'and', 'lam', '##u', ',', 'as', 'well', 'as', 'parts', 'of', 'man', '##der', '##a', ',', 'wa', '##ji', '##r', ',', 'ga', '##rissa', ',', 'bari', '##ngo', ',', 'lai', '##ki', '##pia', ',', 'ki', '##li', '##fi', 'and', 'kw', '##ale', '.', 'households', 'in', 'this', 'category', 'are', 'marginal', '##ly', 'able', 'to', 'meet', 'their', 'minimum', 'food', 'needs', 'but', 'only', 'by', 'more', 'rapidly', 'de', '##ple', '##ting', 'their', 'assets', 'and', 'thus', 'under', '##mini', '##ng', 'their', 'food', 'consumption', '.', 'in', 'the', 'absence', 'of', 'adequate', 'cross', '-', 'sector', '##al', 'interventions', ',', 'more', 'areas', 'and', 'households', 'in', 'these', 'counties', 'are', 'expected', 'to', 'fall', 'into', 'this', 'phase', 'by', 'october', '2017', '.']\n",
      "\n",
      "Original text:  While aid imports have held up recently, commercial food and fuel imports remain well short of pre-blockade averages. I am particularly concerned about the recent decline of commercial food imports through the Red Sea ports. Pressure on the currency and a liquidity crisis in the Yemeni banking system make imports less viable for traders. Confidence among commercial shipping companies has eroded due to delays, including as a result of inspections undertaken by the Saudiled Coalition after these vessels have been cleared by UNVIM.\n",
      "['while', 'aid', 'imports', 'have', 'held', 'up', 'recently', ',', 'commercial', 'food', 'and', 'fuel', 'imports', 'remain', 'well', 'short', 'of', 'pre', '-', 'blockade', 'averages', '.', 'i', 'am', 'particularly', 'concerned', 'about', 'the', 'recent', 'decline', 'of', 'commercial', 'food', 'imports', 'through', 'the', 'red', 'sea', 'ports', '.', 'pressure', 'on', 'the', 'currency', 'and', 'a', 'liquid', '##ity', 'crisis', 'in', 'the', 'yemen', '##i', 'banking', 'system', 'make', 'imports', 'less', 'viable', 'for', 'traders', '.', 'confidence', 'among', 'commercial', 'shipping', 'companies', 'has', 'eroded', 'due', 'to', 'delays', ',', 'including', 'as', 'a', 'result', 'of', 'inspections', 'undertaken', 'by', 'the', 'saudi', '##led', 'coalition', 'after', 'these', 'vessels', 'have', 'been', 'cleared', 'by', 'un', '##vi', '##m', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Original text: \", train_df[\"text\"][i])\n",
    "    print(tokenize_bert(train_df[\"text\"][i], tokenizer))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "\n",
    "\n",
    "def create_x_batches_bert(df, batch_size: int, tokenizer, max_document_length: int):\n",
    "    \"\"\"\n",
    "    Create batches for any given dataset (train/validation/test) - X\n",
    "    :param df: dataframe, pd.DataFrame\n",
    "    :param batch_size: batch size, int\n",
    "    :param tokenizer: BERT tokenizer, BertTokenizer\n",
    "    :param max_document_length: maximum document length, int\n",
    "    :return: batches, list of np.array of shape (batch_size, max_seq_len)\n",
    "    \"\"\"\n",
    "    n_batches = len(df) // batch_size + 1\n",
    "    print(\"Number of batches: \", n_batches)\n",
    "    batches = []\n",
    "    for i in range(n_batches):\n",
    "        batch = df.iloc[i * batch_size : (i + 1) * batch_size]\n",
    "        batch_list = batch[\"text\"].tolist()\n",
    "        tokenized_text = tokenizer(\n",
    "            batch_list,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_document_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # for key in tokenized_text:\n",
    "        #     tokenized_text[key] = tokenized_text[key]\n",
    "        batches.append(tokenized_text)\n",
    "    return batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "def create_y_batches(df, batch_size: int):\n",
    "    \"\"\"\n",
    "    Create batches for any given dataset (train/validation/test) - y\n",
    "    :param df: dataframe, pd.DataFrame\n",
    "    :param batch_size: batch size, int\n",
    "    :return: batches of labels, np.ndarray of shape (n_batches, batch_size)\n",
    "    \"\"\"\n",
    "    n_batches = len(df) // batch_size + 1\n",
    "    print(\"Number of batches: \", n_batches)\n",
    "    batches = []\n",
    "    for batch_idx in range(n_batches):\n",
    "        if batch_idx != n_batches - 1:\n",
    "            batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        else:\n",
    "            batch = np.zeros((len(df) - batch_idx * batch_size), dtype=np.int32)\n",
    "        current_batch_size = batch.shape[0]\n",
    "        for doc_idx in range(current_batch_size):\n",
    "            batch[doc_idx] = df.iloc[batch_idx * batch_size + doc_idx]['label']\n",
    "        batches.append(batch)\n",
    "    return batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  379\n",
      "Number of batches:  379\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n",
      "Number of batches:  82\n"
     ]
    }
   ],
   "source": [
    "batches = {\n",
    "    \"train\": {\n",
    "        \"x\": create_x_batches_bert(train_df, BATCH_SIZE, tokenizer, MAX_DOCUMENT_LENGTH),\n",
    "        \"y\": create_y_batches(train_df, BATCH_SIZE)\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"x\": create_x_batches_bert(val_df, BATCH_SIZE, tokenizer, MAX_DOCUMENT_LENGTH),\n",
    "        \"y\": create_y_batches(val_df, BATCH_SIZE)\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"x\": create_x_batches_bert(test_df, BATCH_SIZE, tokenizer, MAX_DOCUMENT_LENGTH),\n",
    "        \"y\": create_y_batches(test_df, BATCH_SIZE)\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "379"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches['train']['x'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "379"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches['train']['y'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][0].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 100])"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][0][\"input_ids\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "(32,)"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14, 100])"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][-1][\"input_ids\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "(14,)"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 1999, 2804,  ...,    0,    0,    0],\n        [ 101, 2045, 2024,  ..., 1997, 2158,  102],\n        [ 101, 2096, 4681,  ...,  102,    0,    0],\n        ...,\n        [ 101, 3229, 2000,  ...,    0,    0,    0],\n        [ 101, 5924, 1005,  ...,    0,    0,    0],\n        [ 101, 2019, 4358,  ..., 2216, 8941,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1]])}"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 9,  3,  5,  0,  3,  9,  9,  1,  4,  4,  9,  3,  8,  9,  4,  9,  9,\n        3,  9,  2,  1, 10,  3,  5,  3,  4,  3,  9,  3, 11,  7, 10])"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': array([[  101,  2033,  3022, ...,     0,     0,     0],\n       [  101,  3053,  2093, ...,  2431,  1997,   102],\n       [  101,  2090,  3134, ...,     0,     0,     0],\n       ...,\n       [  101,  1029, 11325, ...,     0,     0,     0],\n       [  101,  2004,  2148, ...,     0,     0,     0],\n       [  101,  5259,  2075, ...,     0,     0,     0]], dtype=int64), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]], dtype=int64)}"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['x'][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 4, 11,  4,  3,  3,  4,  9,  8,  4,  8,  0,  4, 11,  3])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[\"train\"]['y'][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model definition and forward function\n",
    "Define the class **`ClassificationBERTModel`** as a PyTorch model. In the initialization procedure, the model receives the loaded BERT model and stores it as the model's parameter. The parameters of the BERT model should be trainable. The forward function of the model receives a batch of data, passes this batch to BERT, and achieves the corresponding document embeddings from the output of BERT. Similar to the previous task, the document embeddings are used for classification by linearly transforming document embeddings to the vectors with the number of classes, followed by applying Softmax."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationBERTModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(ClassificationBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: batch of data, np.array\n",
    "        :return: logits, np.array\n",
    "        \"\"\"\n",
    "        # get the document embeddings from BERT\n",
    "        x = self.bert(\n",
    "            input_ids=x[\"input_ids\"],\n",
    "            attention_mask=x[\"attention_mask\"],\n",
    "            token_type_ids=x[\"token_type_ids\"],\n",
    "            return_dict=True\n",
    "        )\n",
    "        # get the last hidden state of the [CLS] token\n",
    "        x = x[\"last_hidden_state\"][:, 0, :]\n",
    "        # linearly transform document embeddings to the vectors with the number of classes\n",
    "        # and apply Softmax\n",
    "        # Log Softmax is used for numerical stability\n",
    "        return torch.nn.LogSoftmax(dim=-1)(self.linear(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and overall functionality\n",
    "Train the model in a similar fashion to the previous task, namely with the proper loss function, optimization, and early stopping."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "clf_bert_model = ClassificationBERTModel(bert_model, np.unique(train_df[\"label\"]).shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "LOSS = \"nll\"\n",
    "if LOSS == \"nll\":\n",
    "    criterion = nn.NLLLoss()\n",
    "else:\n",
    "    # Cross Entropy is the default loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "optim_fn = \"adam\"\n",
    "\n",
    "if optim_fn == \"sgd\":\n",
    "    optimizer = optim.SGD(clf_bert_model.parameters(), lr=LR)\n",
    "else:\n",
    "    # Adam is the default optimizer\n",
    "    optimizer = optim.Adam(clf_bert_model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def do_train_bert(model, criterion, optimizer, batches, epochs: int = 20, patience: int = 3,):\n",
    "    \"\"\"\n",
    "    Train the model for a number of epochs\n",
    "    :param model: model to train, ClassificationBERTModel\n",
    "    :param criterion: loss function, nn.CrossEntropyLoss or nn.NLLLoss\n",
    "    :param optimizer: optimization method, optim.Adam or optim.SGD\n",
    "    :param batches: batches of data, list of (np.array, np.array)\n",
    "    :param epochs: number of epochs, int (default: 20)\n",
    "    :param patience: number of epochs to wait before early stopping, int (default: 3)\n",
    "    :return: best model, ClassificationAverageModel\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    X_train = batches[\"train\"][\"x\"]\n",
    "    y_train = batches[\"train\"][\"y\"]\n",
    "    X_val = batches[\"val\"][\"x\"]\n",
    "    y_val = batches[\"val\"][\"y\"]\n",
    "    patience_counter = 0\n",
    "    loss = torch.tensor(0.0)\n",
    "\n",
    "    print(\"Start training!\")\n",
    "    print(\"=\" * len(\"Start training!\"))\n",
    "    print(f\"Optimizer: {optim_fn}, Loss: {LOSS}, LR: {LR}\")\n",
    "    print(f\"Epochs: {epochs}, Patience: {patience}\")\n",
    "    print(\"=\" * len(f\"Epochs: {epochs}, Patience: {patience}\"))\n",
    "    print()\n",
    "\n",
    "    # LOOP OVER EPOCHS\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc=\"Epochs\", total=epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        model.train()\n",
    "        # lists of all predictions and labels to calculate accuracy\n",
    "        y_pred_all = []\n",
    "        y_true_all = []\n",
    "        losses = []\n",
    "        for x, y in tqdm(zip(X_train, y_train), desc=\"Training\", total=len(X_train)):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            y_true = torch.LongTensor(y)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # to calculate accuracy\n",
    "            y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "            y_true_all.append(y_true.tolist())\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "        y_true_all = np.concatenate(y_true_all)\n",
    "        acc = accuracy_score(y_true_all, y_pred_all)\n",
    "        print(f\"Train accuracy: {acc}, Train loss: {np.mean(losses)}\")\n",
    "\n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        # lists of all predictions and labels to calculate accuracy\n",
    "        y_pred_all = []\n",
    "        y_true_all = []\n",
    "        for x, y in zip(X_val, y_val):\n",
    "            y_pred = model(x)\n",
    "            y_true = torch.LongTensor(y)\n",
    "            y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "            y_true_all.append(y_true.tolist())\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "        y_true_all = np.concatenate(y_true_all)\n",
    "        acc = accuracy_score(y_true_all, y_pred_all)\n",
    "        print(f\"Validation Accuracy: {acc}\")\n",
    "\n",
    "        # EARLY STOPPING\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model, \"best_model_bert.pt\")\n",
    "            print(\"Best model updated\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "    torch.save(model, \"last_model_bert.pt\")\n",
    "    print(\"Training finished\")\n",
    "    print(\"Best validation accuracy: \", best_acc)\n",
    "    print(\"Best epoch: \", best_epoch)\n",
    "    return best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "===============\n",
      "Optimizer: adam, Loss: nll, LR: 0.001\n",
      "Epochs: 4, Patience: 3\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epochs:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa83c2b333814e57986db560005cc451"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e6fc09c2c540bbb04a03b0ec3859d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6976052848885219, Train loss: 1.1225271107810784\n",
      "Validation Accuracy: 0.6987673343605547\n",
      "Best model updated\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "add4f90bbb9d461e9e455f1a8ac3130a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6984310487200661, Train loss: 1.1149522324036167\n",
      "Validation Accuracy: 0.6864406779661016\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43420f99e977409cbda3d6c3502c884f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6956234516928158, Train loss: 1.1297726215190182\n",
      "Validation Accuracy: 0.6768104776579353\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/379 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92c35178eb764453b38b4f8ea55882a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7006606110652354, Train loss: 1.0906477365298761\n",
      "Validation Accuracy: 0.7041602465331279\n",
      "Best model updated\n",
      "Training finished\n",
      "Best validation accuracy:  0.7041602465331279\n",
      "Best epoch:  4\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 4\n",
    "DO_TRAIN_BERT = True\n",
    "\n",
    "if DO_TRAIN_BERT:\n",
    "    best_model_bert = do_train_bert(\n",
    "        model=clf_bert_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batches=batches,\n",
    "        epochs=N_EPOCHS,\n",
    "        patience=3,\n",
    "    )\n",
    "else:\n",
    "    best_model_bert = torch.load(\"best_model_bert.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Set Evaluation\n",
    "After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "def predict_bert(bert_model, input):\n",
    "    \"\"\"\n",
    "    Predict the classes of the test set\n",
    "    :param model: trained model, ClassificationBERTModel\n",
    "    :param input: test set, list of np.array\n",
    "    :return: predicted classes, torch.Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    bert_model.eval()\n",
    "    y_pred_all = []\n",
    "    for x in input:\n",
    "        y_pred = bert_model(x)\n",
    "        y_pred_all.append(torch.argmax(y_pred, dim=1).tolist())\n",
    "    return np.concatenate(y_pred_all)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "\n",
    "y_pred_test = predict_bert(best_model_bert, batches[\"test\"][\"x\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "assert y_pred_test.shape == (test_df.shape[0],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7082851637764933"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = accuracy_score(test_df[\"label\"], y_pred_test)\n",
    "acc_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Reporting\n",
    "Report the results of the best performing model on the validation and test set in a table."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "y_pred_val = predict_bert(best_model_bert, batches[\"val\"][\"x\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7041602465331279"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_val = accuracy_score(val_df[\"label\"], y_pred_val)\n",
    "acc_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7041602465331279\n",
      "Test accuracy: 0.7082851637764933\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation accuracy: {acc_val}\")\n",
    "print(f\"Test accuracy: {acc_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "report_bert = pd.DataFrame(\n",
    "    {\n",
    "        \"Validation Accuracy\": [acc_val],\n",
    "        \"Test Accuracy\": [acc_test],\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "   Validation Accuracy  Test Accuracy\n0              0.70416       0.708285",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation Accuracy</th>\n      <th>Test Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.70416</td>\n      <td>0.708285</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}